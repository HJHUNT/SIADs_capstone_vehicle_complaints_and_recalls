{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSUMER COMPLAINTS\n",
    "\n",
    "# The COMPLAINTS file contains all safety-related defect complaints received \n",
    "# by NHTSA since January 1, 1995.\n",
    "\n",
    "# File characteristics:\n",
    "\n",
    "# -  All the records are TAB delimited\n",
    "# -  All dates are in YYYYMMDD format\n",
    "\n",
    "# -  Maximum record length: 2824\n",
    "\n",
    "# Change log:\n",
    "# 1. Fields 21 - 46 were added on Sept. 14, 2007\n",
    "# 2. Changed flat file extension from .lst to .txt on Sept. 14, 2007\n",
    "# 3. Field 47 was added on Oct. 15, 2007\n",
    "# 4. Field 34 was changed from CHAR(20) to CHAR(30) on Aug. 08, 2008\n",
    "# 5. Field 18 was changed from NUMBER(6) to NUMBER(7) on Jun. 18, 2010\n",
    "# 6. Complaint Type 'MIVQ' was added to Field 21 list on Mar. 21, 2013\n",
    "# 7. Complaint Type 'MAVQ' was added to Field 21 list on Jan. 17, 2014\n",
    "# 8. Field 48 was added on Apr. 24, 2014\n",
    "# 9. Field 49 was added on Sept. 29, 2015\n",
    "# 10. Flat file content changes May 17 - June 17, 2021\n",
    "# 11. Information message updated on June 28, 2021\n",
    "\n",
    "# =======\n",
    "# May 17 - June 17, 2021 - Flat file content changes.\n",
    "# * Previously blank Y/N fields (such as crash or fire) will now show as N.\n",
    "# * Previously blank values for numeric fields will now show as zero.\n",
    "# * Manufacturer name, make, model and component name of the product(s) in a complaint may have changed over time and the new flat file will now reflect them.\n",
    "# * If a complaint had multiple dealer contacts, only a single dealer's contact information will now show.\n",
    "# * Additional minor differences due to data cleanup in a relatively small number of records in the flat file.\n",
    "# =======\n",
    "# June 28, 2021 - Flat file content changes.\n",
    "# The NHTSA system that generates the complaints file underwent an update during the weekend of May 16-17, 2021. The update has caused discrepancies between the contents of the complaints file between the version posted on Friday, May 15, 2021 (before the system update) and the versions posted daily since Monday, May 17, 2021 (after the system update) and continuing to date. Lookup of complaints on the NHTSA public website are unaffected.\n",
    "# We are working to resolve the issue. In the meantime, we will continue to publish data daily as it will contain newly received complaints by NHTSA. The complaint data is included in the single FLAT_CMPL.zip and the COMPLAINTS_RECEIVED_YYYY-YYYY.zip files, which contain the same data broken down into 5-year chunks by received date. Note that the format of the complaint files has not and will not change. Once resolved, you may still see minor data differences between the latest version and that from prior to the system update.\n",
    "# We will continue to update this message as needed until the issue is resolved.\n",
    "# =======\n",
    "\n",
    "# Last updated: June 28, 2021\n",
    "\n",
    "# FIELDS:\n",
    "# =======\n",
    "\n",
    "# Field#  Name              Type/Size     Description\n",
    "# ------  ---------         ---------     --------------------------------------\n",
    "# 1       CMPLID            CHAR(9)       NHTSA'S INTERNAL UNIQUE SEQUENCE NUMBER.\n",
    "#                                         IS AN UPDATEABLE FIELD,THUS DATA FOR A\n",
    "#                                         GIVEN RECORD POTENTIALLY COULD CHANGE FROM\n",
    "#                                         ONE DATA OUTPUT FILE TO THE NEXT.\n",
    "# 2       ODINO             CHAR(9)       NHTSA'S INTERNAL REFERENCE NUMBER.\n",
    "#                                         THIS NUMBER MAY BE REPEATED FOR\n",
    "#                                         MULTIPLE COMPONENTS.\n",
    "#                                         ALSO, IF LDATE IS PRIOR TO DEC 15, 2002,\n",
    "#                                         THIS NUMBER MAY BE REPEATED FOR MULTIPLE\n",
    "#                                         PRODUCTS OWNED BY THE SAME COMPLAINANT.\n",
    "# 3       MFR_NAME          CHAR(40)      MANUFACTURER'S NAME\n",
    "# 4       MAKETXT           CHAR(25)      VEHICLE/EQUIPMENT MAKE\n",
    "# 5       MODELTXT          CHAR(256)     VEHICLE/EQUIPMENT MODEL\n",
    "# 6       YEARTXT           CHAR(4)       MODEL YEAR, 9999 IF UNKNOWN or N/A\n",
    "# 7       CRASH             CHAR(1)       WAS VEHICLE INVOLVED IN A CRASH, 'Y' OR 'N'\n",
    "# 8       FAILDATE          CHAR(8)       DATE OF INCIDENT (YYYYMMDD)\n",
    "# 9       FIRE              CHAR(1)       WAS VEHICLE INVOLVED IN A FIRE 'Y' OR 'N'\n",
    "# 10      INJURED           NUMBER(2)     NUMBER OF PERSONS INJURED\n",
    "# 11      DEATHS            NUMBER(2)     NUMBER OF FATALITIES\n",
    "# 12      COMPDESC          CHAR(128)     SPECIFIC COMPONENT'S DESCRIPTION\n",
    "# 13      CITY              CHAR(30)      CONSUMER'S CITY\n",
    "# 14      STATE             CHAR(2)       CONSUMER'S STATE CODE\n",
    "# 15      VIN               CHAR(11)      VEHICLE'S VIN#\n",
    "# 16      DATEA             CHAR(8)       DATE ADDED TO FILE (YYYYMMDD)\n",
    "# 17      LDATE             CHAR(8)       DATE COMPLAINT RECEIVED BY NHTSA (YYYYMMDD)\n",
    "# 18      MILES             NUMBER(7)     VEHICLE MILEAGE AT FAILURE\n",
    "# 19      OCCURENCES        NUMBER(4)     NUMBER OF OCCURRENCES\n",
    "# 20      CDESCR            CHAR(2048)    DESCRIPTION OF THE COMPLAINT\n",
    "# 21      CMPL_TYPE         CHAR(4)       SOURCE OF COMPLAINT CODE:\n",
    "#                                           CAG  =CONSUMER ACTION GROUP\n",
    "#                                           CON  =FORWARDED FROM A CONGRESSIONAL OFFICE\n",
    "#                                           DP   =DEFECT PETITION,RESULT OF A DEFECT PETITION\n",
    "#                                           EVOQ =HOTLINE VOQ\n",
    "#                                           EWR  =EARLY WARNING REPORTING\n",
    "#                                           INS  =INSURANCE COMPANY\n",
    "#                                           IVOQ =NHTSA WEB SITE\n",
    "#                                           LETR =CONSUMER LETTER\n",
    "#                                           MAVQ =NHTSA MOBILE APP\n",
    "#                                           MIVQ =NHTSA MOBILE APP\n",
    "#                                           MVOQ =OPTICAL MARKED VOQ\n",
    "#                                           RC   =RECALL COMPLAINT,RESULT OF A RECALL INVESTIGATION\n",
    "#                                           RP   =RECALL PETITION,RESULT OF A RECALL PETITION\n",
    "#                                           SVOQ =PORTABLE SAFETY COMPLAINT FORM (PDF)\n",
    "#                                           VOQ  =NHTSA VEHICLE OWNERS QUESTIONNAIRE\n",
    "# 22      POLICE_RPT_YN     CHAR(1)       WAS INCIDENT REPORTED TO POLICE 'Y' OR 'N'\n",
    "# 23      PURCH_DT          CHAR(8)       DATE PURCHASED (YYYYMMDD)\n",
    "# 24      ORIG_OWNER_YN     CHAR(1)       WAS ORIGINAL OWNER 'Y' OR 'N'\n",
    "# 25      ANTI_BRAKES_YN    CHAR(1)       ANTI-LOCK BRAKES 'Y' OR 'N'\n",
    "# 26      CRUISE_CONT_YN    CHAR(1)       CRUISE CONTROL 'Y' OR 'N'\n",
    "# 27      NUM_CYLS          NUMBER(2)     NUMBER OF CYLINDERS\n",
    "# 28      DRIVE_TRAIN       CHAR(4)       DRIVE TRAIN TYPE [AWD,4WD,FWD,RWD]\n",
    "# 29      FUEL_SYS          CHAR(4)       FUEL SYSTEM CODE:\n",
    "#                                            FI =FUEL INJECTION\n",
    "#                                            TB =TURBO\n",
    "# 30      FUEL_TYPE         CHAR(4)       FUEL TYPE CODE:\n",
    "#                                            BF =BIFUEL\n",
    "#                                            CN =CNG/LPG\n",
    "#                                            DS =DIESEL\n",
    "#                                            GS =GAS\n",
    "#                                            HE =HYBRID ELECTRIC\n",
    "# 31      TRANS_TYPE        CHAR(4)       VEHICLE TRANSMISSION TYPE [AUTO, MAN]\n",
    "# 32      VEH_SPEED         NUMBER(3)     VEHICLE SPEED\n",
    "# 33      DOT               CHAR(20)      DEPARTMENT OF TRANSPORTATION TIRE IDENTIFIER\n",
    "# 34      TIRE_SIZE         CHAR(30)      TIRE SIZE\n",
    "# 35      LOC_OF_TIRE       CHAR(4)       LOCATION OF TIRE CODE:\n",
    "#                                            FSW =DRIVER SIDE FRONT\n",
    "#                                            DSR =DRIVER SIDE REAR\n",
    "#                                            FTR =PASSENGER SIDE FRONT\n",
    "#                                            PSR =PASSENGER SIDE REAR\n",
    "#                                            SPR =SPARE\n",
    "# 36      TIRE_FAIL_TYPE    CHAR(4)       TYPE OF TIRE FAILURE CODE:\n",
    "#                                            BST =BLISTER\n",
    "#                                            BLW =BLOWOUT\n",
    "#                                            TTL =CRACK\n",
    "#                                            OFR =OUT OF ROUND\n",
    "#                                            TSW =PUNCTURE\n",
    "#                                            TTR =ROAD HAZARD\n",
    "#                                            TSP =TREAD SEPARATION\n",
    "# 37      ORIG_EQUIP_YN     CHAR(1)       WAS PART ORIGINAL EQUIPMENT 'Y' OR 'N'\n",
    "# 38      MANUF_DT          CHAR(8)       DATE OF MANUFACTURE (YYYYMMDD)\n",
    "# 39      SEAT_TYPE         CHAR(4)       TYPE OF CHILD SEAT CODE:\n",
    "#                                            B  =BOOSTER\n",
    "#                                            C  =CONVERTIBLE\n",
    "#                                            I  =INFANT\n",
    "#                                            IN =INTEGRATED\n",
    "#                                            TD =TODDLER\n",
    "# 40     RESTRAINT_TYPE     CHAR(4)       INSTALLATION SYSTEM CODE;\n",
    "#                                            A =VEHICLE SAFETY BELT\n",
    "#                                            B =LATCH SYSTEM\n",
    "# 41     DEALER_NAME        CHAR(40)      DEALER'S NAME\n",
    "# 42     DEALER_TEL         CHAR(20)      DEALER'S TELEPHONE NUMBER\n",
    "# 43     DEALER_CITY        CHAR(30)      DEALER'S CITY\n",
    "# 44     DEALER_STATE       CHAR(2)       DEALER'S STATE CODE\n",
    "# 45     DEALER_ZIP         CHAR(10)      DEALER'S ZIPCODE\n",
    "# 46     PROD_TYPE          CHAR(4)       PRODUCT TYPE CODE:\n",
    "#                                            V =VEHICLE\n",
    "#                                            T =TIRES\n",
    "#                                            E =EQUIPMENT\n",
    "#                                            C =CHILD RESTRAINT\n",
    "# 47     REPAIRED_YN        CHAR(1)       WAS DEFECTIVE TIRE REPAIRED 'Y' OR 'N'\n",
    "# 48     MEDICAL_ATTN       CHAR(1)       WAS MEDICAL ATTENTION REQUIRED 'Y' OR 'N'\n",
    "# 49     VEHICLES_TOWED_YN  CHAR(1)       WAS VEHICLE TOWED 'Y' OR 'N'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# https://www.nhtsa.gov/nhtsa-datasets-and-apis#recalls\n",
    "filename = \"C:\\\\Repo\\\\SIADs_Audio_Text_SRS\\\\Datasets\\\\COMPLAINTS_RECEIVED_2025-2025.txt\"\n",
    "# read in C:\\Repo\\SIADs_Audio_Text_SRS\\Example\\COMPLAINTS_RECEIVED_2025-2025.txt into a pandas dataframe, where the columns are RCL\n",
    "df_complaints = pd.read_csv(filename, sep='\\t', header=None, index_col=0)\n",
    "df_complaints.columns = ['ODINO', 'MFR_NAME', 'MAKETXT', 'MODELTXT', 'YEARTXT', 'CRASH', 'FAILDATE', 'FIRE', 'INJURED', 'DEATHS', 'COMPDESC', 'CITY', 'STATE', 'VIN', 'DATEA', 'LDATE', 'MILES', 'OCCURENCES', 'CDESCR', 'CMPL_TYPE', 'POLICE_RPT_YN', 'PURCH_DT', 'ORIG_OWNER_YN', 'ANTI_BRAKES_YN', 'CRUISE_CONT_YN', 'NUM_CYLS', 'DRIVE_TRAIN', 'FUEL_SYS', 'FUEL_TYPE',\n",
    "              'TRANS_TYPE', 'VEH_SPEED', 'DOT', 'TIRE_SIZE', 'LOC_OF_TIRE', 'TIRE_FAIL_TYPE', 'ORIG_EQUIP_YN', 'MANUF_DT', 'SEAT_TYPE', 'RESTRAINT_TYPE', 'DEALER_NAME', 'DEALER_TEL', 'DEALER_CITY', 'DEALER_STATE', 'DEALER_ZIP', 'PROD_TYPE', 'REPAIRED_YN', 'MEDICAL_ATTN', 'VEHICLES_TOWED_YN']\n",
    "\n",
    "summary = df_complaints.describe()\n",
    "display(summary)\n",
    "\n",
    "deadly_complaints = df_complaints[df_complaints[\"DEATHS\"] > 0]\n",
    "#print(deadly_complaints)\n",
    "\n",
    "# print any of the complaints that lead to a death\n",
    "display(deadly_complaints[[\"ODINO\", \"MFR_NAME\", \"MAKETXT\", \"MODELTXT\", \"YEARTXT\", \"DEATHS\", \"CDESCR\"]])\n",
    "# print the tesla complaints that lead to a death\n",
    "print(deadly_complaints[deadly_complaints[\"MFR_NAME\"] == \"Tesla, Inc.\"][\"CDESCR\"].values)\n",
    "\n",
    "# display columns 11 through 25\n",
    "#display(df_complaints)\n",
    "\n",
    "sub_df = df_complaints[[\"ODINO\", \"MFR_NAME\", \"MAKETXT\", \"MODELTXT\", \"YEARTXT\", \"CDESCR\"]]\n",
    "display(sub_df)\n",
    "#display(read_complaints_received())\n",
    "# print all the unique COMPDESC values\n",
    "COMPDESC_list = df_complaints[\"COMPDESC\"].unique()\n",
    "print(COMPDESC_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECALLS\n",
    "\n",
    "# The RECALL file contains all NHTSA safety-related defect and compliance \n",
    "# campaigns since 1967.\n",
    "\n",
    "# File characteristics:\n",
    "\n",
    "# -  All the records are TAB delimited\n",
    "# -  All dates are in YYYYMMDD format\n",
    "\n",
    "# -  Maximum Record length: 9109\n",
    "\n",
    "# Change log:\n",
    "# 1.Field# 23 added as of Sept. 14, 2007\n",
    "# 2.Changed flat file extension from .lst to .txt as of Sept. 14, 2007\n",
    "# 3.Field# 24 added as of March 14, 2008\n",
    "# 4.Field#s 25,26,27 added as of March 23, 2020\n",
    "\n",
    "# Last Updated March 23, 2020\n",
    "\n",
    "\n",
    "# FIELDS:\n",
    "# =======\n",
    "\n",
    "# Field#   Name                Type/Size   Description                      \n",
    "# ------   ---------           ---------   --------------------------------------\n",
    "# 1        RECORD_ID           NUMBER(9)   RUNNING SEQUENCE NUMBER, \n",
    "#                                           WHICH UNIQUELY IDENTIFIES THE RECORD.\n",
    "# 2        CAMPNO              CHAR(12)    NHTSA CAMPAIGN NUMBER\n",
    "# 3        MAKETXT             CHAR(25)    VEHICLE/EQUIPMENT MAKE\n",
    "# 4        MODELTXT            CHAR(256)   VEHICLE/EQUIPMENT MODEL\n",
    "# 5        YEARTXT             CHAR(4)     MODEL YEAR, 9999 IF UNKNOWN or N/A\n",
    "# 6        MFGCAMPNO           CHAR(20)    MFR CAMPAIGN NUMBER\n",
    "# 7        COMPNAME            CHAR(256)   COMPONENT DESCRIPTION\n",
    "# 8        MFGNAME             CHAR(40)    MANUFACTURER THAT FILED DEFECT/NONCOMPLIANCE REPORT\n",
    "# 9        BGMAN               CHAR(8)     BEGIN DATE OF MANUFACTURING\n",
    "# 10       ENDMAN              CHAR(8)     END DATE OF MANUFACTURING\n",
    "# 11       RCLTYPECD           CHAR(4)     VEHICLE, EQUIPMENT OR TIRE REPORT\n",
    "# 12       POTAFF              NUMBER(9)   POTENTIAL NUMBER OF UNITS AFFECTED               \n",
    "# 13       ODATE               CHAR(8)     DATE OWNER NOTIFIED BY MFR\n",
    "# 14       INFLUENCED_BY       CHAR(4)     RECALL INITIATOR (MFR/OVSC/ODI)\n",
    "# 15       MFGTXT              CHAR(40)    MANUFACTURERS OF RECALLED VEHICLES/PRODUCTS\n",
    "# 16       RCDATE              CHAR(8)     REPORT RECEIVED DATE\n",
    "# 17       DATEA               CHAR(8)     RECORD CREATION DATE\n",
    "# 18       RPNO                CHAR(3)     REGULATION PART NUMBER\n",
    "# 19       FMVSS               CHAR(10)    FEDERAL MOTOR VEHICLE SAFETY STANDARD NUMBER\n",
    "# 20       DESC_DEFECT         CHAR(2000)  DEFECT SUMMARY\n",
    "# 21       CONEQUENCE_DEFECT   CHAR(2000)  CONSEQUENCE SUMMARY\t\n",
    "# 22       CORRECTIVE_ACTION   CHAR(2000)  CORRECTIVE SUMMARY\n",
    "# 23       NOTES               CHAR(2000)  RECALL NOTES\n",
    "# 24       RCL_CMPT_ID         CHAR(27)    NUMBER THAT UNIQUELY IDENTIFIES A RECALLED COMPONENT.\n",
    "# 25       MFR_COMP_NAME       CHAR(50)    MANUFACTURER-SUPPLIED COMPONENT NAME\n",
    "# 26       MFR_COMP_DESC       CHAR(200)   MANUFACTURER-SUPPLIED COMPONENT DESCRIPTION\n",
    "# 27       MFR_COMP_PTNO       CHAR(100)   MANUFACTURER-SUPPLIED COMPONENT PART NUMBER\n",
    "\n",
    "# read in C:\\Repo\\SIADs_Audio_Text_SRS\\Datasets\\FLAT_RCL.txt\n",
    "# there are only 24 columns in the file, so we need to specify the column names\n",
    "# https://www.nhtsa.gov/nhtsa-datasets-and-apis#recalls\n",
    "df_recall = pd.read_csv(\"C:\\\\Repo\\\\SIADs_Audio_Text_SRS\\\\Datasets\\\\FLAT_RCL.txt\", sep='\\t', header=None, on_bad_lines='skip')\n",
    "# use the column names listed above\n",
    "df_recall.columns = ['RECORD_ID', 'CAMPNO', 'MAKETXT', 'MODELTXT', 'YEARTXT', 'MFGCAMPNO', 'COMPNAME', 'MFGNAME', 'BGMAN', 'ENDMAN', 'RCLTYPECD', 'POTAFF', 'ODATE', 'INFLUENCED_BY', 'MFGTXT', 'RCDATE', 'DATEA', 'RPNO', 'FMVSS', 'DESC_DEFECT', 'CONEQUENCE_DEFECT', 'CORRECTIVE_ACTION', 'NOTES', 'RCL_CMPT_ID', 'MFR_COMP_NAME', 'MFR_COMP_DESC', 'MFR_COMP_PTNO']\n",
    "display(df_recall)\n",
    "\n",
    "# print all the unique COMPDESC values\n",
    "COMPNAME_list = df_recall[\"COMPNAME\"].unique()\n",
    "print(COMPNAME_list)\n",
    "print(len(COMPNAME_list))\n",
    "# state encode the COMPDESC values and create a new column in the dataframe called COMPDESC_StateEncoded\n",
    "df_recall[\"COMPNAME_StateEncoded\"] = df_recall[\"COMPNAME\"].apply(lambda x: hash(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# create a function that will be called from a apply lambda function to process the text from a dataframe with the \"CDESCR\" column\n",
    "def process_text(text):\n",
    "    \"\"\"\n",
    "    Process text by tokenizing, removing stop words, and stemming\n",
    "    \"\"\"\n",
    "    #print(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # make sure the text is not empty and or nan\n",
    "    if not text or pd.isna(text):\n",
    "        return []\n",
    "\n",
    "    # tokenize the text and remove stop words and stem the words\n",
    "    content_cleaned = [stemmer.stem(word) for word in word_tokenize(text.lower()) if word not in stop_words]\n",
    "\n",
    "    # remove the punctuation from the content_cleaned list\n",
    "    content_cleaned = [word for word in content_cleaned if word.isalnum()]\n",
    "    \n",
    "    return content_cleaned\n",
    "\n",
    "# process the text in the \"CDESCR\" column and create a new column \"CDESCR_CLEANED\" with the processed text\n",
    "df_complaints[\"CDESCR_CLEANED\"] = df_complaints[\"CDESCR\"].apply(lambda x: process_text(x))\n",
    "display(df_complaints[[\"CDESCR\", \"CDESCR_CLEANED\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most common words in the \"CDESCR_CLEANED\" column\n",
    "from collections import Counter\n",
    "\n",
    "# create a Counter object from the \"CDESCR_CLEANED\" column\n",
    "word_counter = Counter([word for words in df_complaints[\"CDESCR_CLEANED\"] for word in words])\n",
    "\n",
    "# get the 10 most common words\n",
    "most_common_words = word_counter.most_common(10)\n",
    "print(most_common_words)\n",
    "\n",
    "# get the 10 least common words\n",
    "least_common_words = word_counter.most_common()[:-10:-1]\n",
    "print(least_common_words)\n",
    "\n",
    "# get the 10 most common words in the \"CDESCR_CLEANED\" column for complaints that lead to a death\n",
    "deadly_complaints = df_complaints[df_complaints[\"DEATHS\"] > 0]\n",
    "word_counter_deadly = Counter([word for words in deadly_complaints[\"CDESCR_CLEANED\"] for word in words])\n",
    "most_common_words_deadly = word_counter_deadly.most_common(10)\n",
    "print(most_common_words_deadly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan values from the \"CDESCR\" column and put it into a new dataframe named \"df_complaints_no_nan\"\n",
    "df_complaints_no_nan = df_complaints.dropna(subset=[\"CDESCR\"])\n",
    "# find any instances of the word \"diagnostic\" or \"DTC\" in the \"CDESCR\" column, DTC stands for Diagnostic Trouble Code and is used in the automotive industry for identifying issues with a vehicle\n",
    "diagnostic_complaints = df_complaints_no_nan[df_complaints_no_nan[\"CDESCR\"].str.contains(\"diagnostic|DTC\", case=False)]\n",
    "display(diagnostic_complaints[[\"ODINO\", \"MFR_NAME\", \"MAKETXT\", \"MODELTXT\", \"YEARTXT\", \"CDESCR\", \"CDESCR_CLEANED\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the df_complaints dataframe into a test, train, and validation set with a 70/20/10 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "train_size = 0.7\n",
    "test_size = 0.2\n",
    "validation_size = 0.1\n",
    "\n",
    "\n",
    "train, test = train_test_split(df_complaints, test_size=(1-train_size), random_state=random_state)\n",
    "test, validation = train_test_split(test, test_size=(validation_size/(1-train_size)), random_state=random_state)\n",
    "print(df_complaints.shape)\n",
    "print(train.shape, test.shape, validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the \"CDESCR_CLEANED\" column using the TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "# set the number of dimensions to reduce the vectorized data to\n",
    "num_dimensions = 100\n",
    "\n",
    "\n",
    "# fit the vectorizer on the \"CDESCR_CLEANED\" column and transform the \"CDESCR_CLEANED\" column into a vectorized format\n",
    "# apply a lambda function to join the list of words in the \"CDESCR_CLEANED\" column into a string\n",
    "X_train = vectorizer.fit_transform(train[\"CDESCR_CLEANED\"].apply(lambda x: \" \".join(x)))\n",
    "X_test = vectorizer.transform(test[\"CDESCR_CLEANED\"].apply(lambda x: \" \".join(x)))\n",
    "X_validation = vectorizer.transform(validation[\"CDESCR_CLEANED\"].apply(lambda x: \" \".join(x)))\n",
    "print(X_train.shape, X_test.shape, X_validation.shape)\n",
    "\n",
    "# perform LSA on the vectorized data to reduce the dimensionality\n",
    "lsa = TruncatedSVD(n_components=num_dimensions, random_state=random_state)\n",
    "complaints_vectorized_train = lsa.fit_transform(X_train)\n",
    "vectorized_test = lsa.transform(X_test)\n",
    "complaints_vectorized_validation = lsa.transform(X_validation)\n",
    "print(complaints_vectorized_train.shape, vectorized_test.shape, complaints_vectorized_validation.shape)\n",
    "# print out the words that correspond to the first 10 dimensions of the LSA\n",
    "\n",
    "# create a list of unique manufacturers in the \"MFR_NAME\" column\n",
    "list_of_manufacturers = df_complaints[\"MFR_NAME\"].unique()\n",
    "#print(list_of_manufacturers)\n",
    "\n",
    "# Find the cosine similarity between the first complaint in the test set and all the complaints in the training set\n",
    "# get the first complaint in the test set\n",
    "complaint_test = vectorized_test[5].reshape(1, -1)\n",
    "# get the cosine similarity between the first complaint in the test set and all the complaints in the training set\n",
    "cosine_similarities = cosine_similarity(complaint_test, complaints_vectorized_train)\n",
    "# get the index of the most similar complaint in the training set\n",
    "most_similar_index = cosine_similarities.argmax()\n",
    "print(most_similar_index)\n",
    "# get the most similar complaint in the training set\n",
    "most_similar_complaint_train = train.iloc[most_similar_index]\n",
    "print(most_similar_complaint_train[[\"ODINO\", \"MFR_NAME\", \"MAKETXT\", \"MODELTXT\", \"YEARTXT\", \"CDESCR\"]])\n",
    "print(most_similar_complaint_train[\"CDESCR\"])\n",
    "# get the most similar complaint in the test set\n",
    "most_similar_complaint_test = test.iloc[5]\n",
    "print(most_similar_complaint_test[[\"ODINO\", \"MFR_NAME\", \"MAKETXT\", \"MODELTXT\", \"YEARTXT\", \"CDESCR\"]])\n",
    "print(most_similar_complaint_test[\"CDESCR\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query text to vectorize and find similar complaints to\n",
    "query_text = \"EV not charging\"\n",
    "\n",
    "# process the query text\n",
    "query_text_cleaned = process_text(query_text)\n",
    "# vectorize the query text\n",
    "query_vectorized = vectorizer.transform([\" \".join(query_text_cleaned)])\n",
    "# reduce the dimensionality of the query vector\n",
    "query_vectorized_lsa = lsa.transform(query_vectorized)\n",
    "# find the cosine similarity between the query vector and all the complaints in the training set\n",
    "cosine_similarities_query = cosine_similarity(query_vectorized_lsa, complaints_vectorized_train)\n",
    "# get the index of the most similar complaint in the training set\n",
    "most_similar_index_query = cosine_similarities_query.argmax()\n",
    "# get the most similar complaint in the training set\n",
    "most_similar_complaint_train_query = train.iloc[most_similar_index_query]\n",
    "print(most_similar_complaint_train_query[[\"ODINO\", \"MFR_NAME\", \"MAKETXT\", \"MODELTXT\", \"YEARTXT\", \"CDESCR\"]])\n",
    "print(most_similar_complaint_train_query[\"CDESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functionalize the process of finding similar complaints to a query text\n",
    "def find_similar_complaint(query_text:str, vectorizer, lsa, train):\n",
    "    \"\"\"\n",
    "    Find the most similar complaint to a query text in the training set\n",
    "    \"\"\"\n",
    "    # process the query text\n",
    "    query_text_cleaned = process_text(query_text)\n",
    "    # vectorize the query text\n",
    "    query_vectorized = vectorizer.transform([\" \".join(query_text_cleaned)])\n",
    "    # reduce the dimensionality of the query vector\n",
    "    query_vectorized_lsa = lsa.transform(query_vectorized)\n",
    "    # find the cosine similarity between the query vector and all the complaints in the training set\n",
    "    cosine_similarities_query = cosine_similarity(query_vectorized_lsa, complaints_vectorized_train)\n",
    "    # get the index of the most similar complaint in the training set\n",
    "    most_similar_index_query = cosine_similarities_query.argmax()\n",
    "    # get the most similar complaint in the training set\n",
    "    most_similar_complaint_train_query = train.iloc[most_similar_index_query]\n",
    "    return most_similar_complaint_train_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_stuff = \"rattling noise when driving slowly\"\n",
    "most_similar_complaint = find_similar_complaint(find_similar_stuff, vectorizer, lsa, train)\n",
    "print(most_similar_complaint[[\"ODINO\", \"MFR_NAME\", \"MAKETXT\", \"MODELTXT\", \"YEARTXT\", \"CDESCR\"]])\n",
    "print(most_similar_complaint[\"CDESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class TextClassifier:\n",
    "    def __init__(self, df, column_name:str):\n",
    "        # set the random state for reproducibility\n",
    "        self.random_state = 42\n",
    "        # create a TfidfVectorizer object\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        # set the number of dimensions to reduce the vectorized data to\n",
    "        self.num_dimensions = 100\n",
    "        self.df = df\n",
    "        self.column_name = column_name\n",
    "        self.column_name_cleaned = column_name + \"_CLEANED\"\n",
    "        # create variables to store the training, test, and validation sets for class functions\n",
    "        self.column_name_cleaned = None\n",
    "        self.df_train = None\n",
    "        self.df_test = None\n",
    "        self.df_validation = None\n",
    "        self.x_train_vect = None\n",
    "        self.x_test_vect = None\n",
    "        self.x_validation_vect = None\n",
    "        self.lsa = None\n",
    "        self.vectorized_train = None\n",
    "        self.vectorized_test = None\n",
    "        self.vectorized_validation = None\n",
    "\n",
    "    # create a function that will be called from a apply lambda function to process the text from a dataframe with the \"CDESCR\" column\n",
    "    def process_text(text):\n",
    "        \"\"\"\n",
    "        Process text by tokenizing, removing stop words, and stemming\n",
    "        \"\"\"\n",
    "        #print(text)\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        stemmer = PorterStemmer()\n",
    "        \n",
    "        # make sure the text is not empty and or nan\n",
    "        if not text or pd.isna(text):\n",
    "            return []\n",
    "\n",
    "        # tokenize the text and remove stop words and stem the words\n",
    "        content_cleaned = [stemmer.stem(word) for word in word_tokenize(text.lower()) if word not in stop_words]\n",
    "\n",
    "        # remove the punctuation from the content_cleaned list\n",
    "        content_cleaned = [word for word in content_cleaned if word.isalnum()]\n",
    "        \n",
    "        return content_cleaned\n",
    "    \n",
    "    def process_dataframe(self, train_size=0.7, test_size=0.2, validation_size=0.1):\n",
    "        \"\"\"\n",
    "        Process the text in the \"CDESCR\" column and create a new column \"CDESCR_CLEANED\" with the processed text\n",
    "        \"\"\"\n",
    "        # get current working directory\n",
    "        cwd = os.getcwd()\n",
    "        # change the Example folder to Datasets folder in the cwd path\n",
    "        desired_save_path = cwd.replace(\"Example\", \"Datasets\")\n",
    "        # create a folder path to save the pickle files\n",
    "        if not os.path.exists(desired_save_path):\n",
    "            os.makedirs(desired_save_path)\n",
    "\n",
    "        # check to see if there is a pickle file for the dataframe with the processed text\n",
    "        if os.path.exists(desired_save_path + '//' + self.column_name + \"_df.pkl\"):\n",
    "            # load the pickle file\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_df.pkl\", \"rb\") as f:\n",
    "                self.df = pickle.load(f)\n",
    "        else:\n",
    "            # process the text in the \"CDESCR\" column and create a new column \"CDESCR_CLEANED\" with the processed text\n",
    "            self.df[self.column_name_cleaned] = self.df[self.column_name].apply(lambda x: TextClassifier.process_text(x))\n",
    "            # create a pickle file for the dataframe with the processed text\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_df.pkl\", \"wb\") as f:\n",
    "                pickle.dump(self.df, f)\n",
    "\n",
    "        # split the df_complaints dataframe into a test, train, and validation set with a 70/20/10 split\n",
    "        self.df_train, self.df_test = train_test_split(self.df, test_size=(1-train_size), random_state=self.random_state)\n",
    "        self.df_test, self.df_validation = train_test_split(self.df_test, test_size=(validation_size/(1-train_size)), random_state=self.random_state)\n",
    "\n",
    "        # check to see if there is a pickle file for the vectorizer\n",
    "        if os.path.exists(desired_save_path + '//' + self.column_name + \"_vectorizer.pkl\"):\n",
    "            # load the pickle file\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_vectorizer.pkl\", \"rb\") as f:\n",
    "                self.vectorizer = pickle.load(f)\n",
    "        else:\n",
    "            # fit the vectorizer on the \"CDESCR_CLEANED\" column and transform the \"CDESCR_CLEANED\" column into a vectorized format\n",
    "            # apply a lambda function to join the list of words in the \"CDESCR_CLEANED\" column into a string\n",
    "            self.x_train_vect = self.vectorizer.fit_transform(self.df_train[self.column_name_cleaned].apply(lambda x: \" \".join(x)))\n",
    "            self.x_test_vect = self.vectorizer.transform(self.df_test[self.column_name_cleaned].apply(lambda x: \" \".join(x)))\n",
    "            self.x_validation_vect = self.vectorizer.transform(self.df_validation[self.column_name_cleaned].apply(lambda x: \" \".join(x)))        \n",
    "            #print(self.x_train_vect.shape, self.x_test_vect.shape, self.x_validation_vect.shape)\n",
    "            # create a pickle file for the vectorizer\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_vectorizer.pkl\", \"wb\") as f:\n",
    "                pickle.dump(self.vectorizer, f)\n",
    "\n",
    "        # check to see if there is a pickle file for the lsa\n",
    "        if os.path.exists(desired_save_path + '//' + self.column_name + \"_lsa.pkl\"):\n",
    "            # load the pickle file\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_lsa.pkl\", \"rb\") as f:\n",
    "                self.lsa = pickle.load(f)\n",
    "        else:\n",
    "            # perform LSA on the vectorized data to reduce the dimensionality\n",
    "            self.lsa = TruncatedSVD(n_components=self.num_dimensions, random_state=self.random_state)\n",
    "\n",
    "        # check to see if there is a pickle file for the vectorized training data\n",
    "        if os.path.exists(desired_save_path + '//' + self.column_name + \"_vectorized_train.pkl\"):\n",
    "            # load the pickle file\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_vectorized_train.pkl\", \"rb\") as f:\n",
    "                self.complaints_vectorized_train = pickle.load(f)\n",
    "        else:\n",
    "            self.complaints_vectorized_train = self.lsa.fit_transform(self.x_train_vect)\n",
    "            # create a pickle file for the vectorized training data\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_vectorized_train.pkl\", \"wb\") as f:\n",
    "                pickle.dump(self.complaints_vectorized_train, f)\n",
    "        \n",
    "        # check to see if there is a pickle file for the vectorized test data\n",
    "        if os.path.exists(desired_save_path + '//' + self.column_name + \"_vectorized_test.pkl\"):\n",
    "            # load the pickle file\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_vectorized_test.pkl\", \"rb\") as f:\n",
    "                self.vectorized_test = pickle.load(f)\n",
    "        else:\n",
    "            self.vectorized_test = self.lsa.transform(self.x_test_vect)\n",
    "            # create a pickle file for the vectorized test data\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_vectorized_test.pkl\", \"wb\") as f:\n",
    "                pickle.dump(self.vectorized_test, f)\n",
    "\n",
    "        # check to see if there is a pickle file for the vectorized validation data\n",
    "        if os.path.exists(desired_save_path + '//' + self.column_name + \"_vectorized_validation.pkl\"):\n",
    "            # load the pickle file\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_vectorized_validation.pkl\", \"rb\") as f:\n",
    "                self.complaints_vectorized_validation = pickle.load(f)\n",
    "        else:\n",
    "            self.complaints_vectorized_validation = self.lsa.transform(self.x_validation_vect)\n",
    "            # create a pickle file for the vectorized validation data\n",
    "            with open(desired_save_path + '//' + self.column_name + \"_vectorized_validation.pkl\", \"wb\") as f:\n",
    "                pickle.dump(self.complaints_vectorized_validation, f)\n",
    "\n",
    "        return self.df, self.complaints_vectorized_train, self.vectorized_test, self.complaints_vectorized_validation, self.df_train, self.df_test, self.df_validation\n",
    "    \n",
    "    # A functionalize the process of finding similar complaints to a query text\n",
    "    def find_similar_complaint(self, query_text:str):\n",
    "        \"\"\"\n",
    "        Find the most similar complaint to a query text in the training set\n",
    "        \"\"\"\n",
    "        # process the query text\n",
    "        query_text_cleaned = TextClassifier.process_text(query_text)\n",
    "        # vectorize the query text\n",
    "        query_vectorized = self.vectorizer.transform([\" \".join(query_text_cleaned)])\n",
    "        # reduce the dimensionality of the query vector\n",
    "        query_vectorized_lsa = self.lsa.transform(query_vectorized)\n",
    "        # find the cosine similarity between the query vector and all the complaints in the training set\n",
    "        cosine_similarities_query = cosine_similarity(query_vectorized_lsa, self.complaints_vectorized_train)\n",
    "        # get the index of the most similar complaint in the training set\n",
    "        most_similar_index_query = cosine_similarities_query.argmax()\n",
    "        print(most_similar_index_query)\n",
    "        # get the most similar complaint in the training set\n",
    "        most_similar_complaint_train_query = self.df_train.iloc[most_similar_index_query]\n",
    "        return most_similar_complaint_train_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# https://www.nhtsa.gov/nhtsa-datasets-and-apis#recalls\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# read in C:\\Repo\\SIADs_Audio_Text_SRS\\Example\\COMPLAINTS_RECEIVED_2025-2025.txt into a pandas dataframe, where the columns are RCL\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df_complaints \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRepo\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSIADs_Audio_Text_SRS\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDatasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCOMPLAINTS_RECEIVED_2025-2025.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_complaints\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mODINO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMFR_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAKETXT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMODELTXT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYEARTXT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRASH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAILDATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIRE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINJURED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEATHS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOMPDESC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCITY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVIN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATEA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLDATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMILES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOCCURENCES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCDESCR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCMPL_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOLICE_RPT_YN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPURCH_DT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIG_OWNER_YN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANTI_BRAKES_YN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRUISE_CONT_YN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUM_CYLS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDRIVE_TRAIN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFUEL_SYS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFUEL_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRANS_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVEH_SPEED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIRE_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOC_OF_TIRE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIRE_FAIL_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mORIG_EQUIP_YN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMANUF_DT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEAT_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRESTRAINT_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEALER_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEALER_TEL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEALER_CITY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEALER_STATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEALER_ZIP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROD_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREPAIRED_YN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMEDICAL_ATTN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVEHICLES_TOWED_YN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# create a list of unique manufacturers in the \"MFR_NAME\" column\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# https://www.nhtsa.gov/nhtsa-datasets-and-apis#recalls\n",
    "# read in C:\\Repo\\SIADs_Audio_Text_SRS\\Example\\COMPLAINTS_RECEIVED_2025-2025.txt into a pandas dataframe, where the columns are RCL\n",
    "df_complaints = pd.read_csv(\"C:\\\\Repo\\\\SIADs_Audio_Text_SRS\\\\Datasets\\\\COMPLAINTS_RECEIVED_2025-2025.txt\", sep='\\t', header=None, index_col=0)\n",
    "df_complaints.columns = ['ODINO', 'MFR_NAME', 'MAKETXT', 'MODELTXT', 'YEARTXT', 'CRASH', 'FAILDATE', 'FIRE', 'INJURED', 'DEATHS', 'COMPDESC', 'CITY', 'STATE', 'VIN', 'DATEA', 'LDATE', 'MILES', 'OCCURENCES', 'CDESCR', 'CMPL_TYPE', 'POLICE_RPT_YN', 'PURCH_DT', 'ORIG_OWNER_YN', 'ANTI_BRAKES_YN', 'CRUISE_CONT_YN', 'NUM_CYLS', 'DRIVE_TRAIN', 'FUEL_SYS', 'FUEL_TYPE',\n",
    "              'TRANS_TYPE', 'VEH_SPEED', 'DOT', 'TIRE_SIZE', 'LOC_OF_TIRE', 'TIRE_FAIL_TYPE', 'ORIG_EQUIP_YN', 'MANUF_DT', 'SEAT_TYPE', 'RESTRAINT_TYPE', 'DEALER_NAME', 'DEALER_TEL', 'DEALER_CITY', 'DEALER_STATE', 'DEALER_ZIP', 'PROD_TYPE', 'REPAIRED_YN', 'MEDICAL_ATTN', 'VEHICLES_TOWED_YN']\n",
    "\n",
    "# create a list of unique manufacturers in the \"MFR_NAME\" column\n",
    "list_of_manufacturers = df_complaints[\"MFR_NAME\"].unique()\n",
    "\n",
    "# testing out the functionilzed code\n",
    "\n",
    "# call the TextClassifier class and create an instance of it as text_classifier\n",
    "# pass in the df_complaints dataframe and the \"CDESCR\" column\n",
    "text_classifier = TextClassifier(df_complaints, \"CDESCR\")\n",
    "# process the text in the \"CDESCR\" column\n",
    "text_classifier.process_dataframe()\n",
    "\n",
    "# use one of the complaints in the test set as a query to find the most similar complaint in the training set\n",
    "complaint_test_query = text_classifier.df_test[\"CDESCR\"].iloc[5]\n",
    "print(complaint_test_query)\n",
    "# find the most similar complaint to the complaint test\n",
    "most_similar_complaint = text_classifier.find_similar_complaint(complaint_test_query)\n",
    "# print the most similar complaint with the below columns\n",
    "print(most_similar_complaint[[\"ODINO\", \"MFR_NAME\", \"MAKETXT\", \"MODELTXT\", \"YEARTXT\", \"CDESCR\"]])\n",
    "print(most_similar_complaint[\"CDESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the most similar complaint to the complaint test\n",
    "most_similar_complaint = text_classifier.find_similar_complaint(\"Car won't start\")# and makes a clicking noise\")\n",
    "# print the most similar complaint with the below columns\n",
    "print(most_similar_complaint[[\"ODINO\", \"MFR_NAME\", \"MAKETXT\", \"MODELTXT\", \"YEARTXT\", \"CDESCR\"]])\n",
    "print(most_similar_complaint[\"CDESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio...\n"
     ]
    },
    {
     "ename": "PortAudioError",
     "evalue": "Error opening InputStream: Invalid sample rate [PaErrorCode -9997]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPortAudioError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# call the record_audio function to record audio from the microphone and save it to a file\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecording audio...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecording finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# call the extract_text_from_audio function to extract text from the audio file and save it to a file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Repo\\SIADs_Audio_Text_SRS\\Example\\Extracted_Text.py:98\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m(output_file, duration, freq)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrecord_audio\u001b[39m(output_file, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m441000\u001b[39m):\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# Start recorder with the given values\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# of duration and sample frequency\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     recording \u001b[38;5;241m=\u001b[39m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mprint\u001b[39m(recording)\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# Record audio for the given number of seconds\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Repo\\SIADs_Audio_Text_SRS\\env\\lib\\site-packages\\sounddevice.py:279\u001b[0m, in \u001b[0;36mrec\u001b[1;34m(frames, samplerate, channels, dtype, out, mapping, blocking, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mread_indata(indata)\n\u001b[0;32m    277\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mcallback_exit()\n\u001b[1;32m--> 279\u001b[0m ctx\u001b[38;5;241m.\u001b[39mstart_stream(InputStream, samplerate, ctx\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[0;32m    280\u001b[0m                  ctx\u001b[38;5;241m.\u001b[39minput_dtype, callback, blocking, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Repo\\SIADs_Audio_Text_SRS\\env\\lib\\site-packages\\sounddevice.py:2626\u001b[0m, in \u001b[0;36m_CallbackContext.start_stream\u001b[1;34m(self, StreamClass, samplerate, channels, dtype, callback, blocking, **kwargs)\u001b[0m\n\u001b[0;32m   2623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstart_stream\u001b[39m(\u001b[38;5;28mself\u001b[39m, StreamClass, samplerate, channels, dtype, callback,\n\u001b[0;32m   2624\u001b[0m                  blocking, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2625\u001b[0m     stop()  \u001b[38;5;66;03m# Stop previous playback/recording\u001b[39;00m\n\u001b[1;32m-> 2626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m StreamClass(samplerate\u001b[38;5;241m=\u001b[39msamplerate,\n\u001b[0;32m   2627\u001b[0m                               channels\u001b[38;5;241m=\u001b[39mchannels,\n\u001b[0;32m   2628\u001b[0m                               dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2629\u001b[0m                               callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m   2630\u001b[0m                               finished_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinished_callback,\n\u001b[0;32m   2631\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m   2633\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m _last_callback\n",
      "File \u001b[1;32mc:\\Repo\\SIADs_Audio_Text_SRS\\env\\lib\\site-packages\\sounddevice.py:1440\u001b[0m, in \u001b[0;36mInputStream.__init__\u001b[1;34m(self, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1409\u001b[0m              device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, latency\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1410\u001b[0m              extra_settings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, finished_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1411\u001b[0m              clip_off\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither_off\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, never_drop_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1412\u001b[0m              prime_output_buffers_using_stream_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"PortAudio input stream (using NumPy).\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \n\u001b[0;32m   1415\u001b[0m \u001b[38;5;124;03m    This has the same methods and attributes as `Stream`, except\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \n\u001b[0;32m   1439\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1440\u001b[0m     _StreamBase\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m, wrap_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1441\u001b[0m                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_remove_self(\u001b[38;5;28mlocals\u001b[39m()))\n",
      "File \u001b[1;32mc:\\Repo\\SIADs_Audio_Text_SRS\\env\\lib\\site-packages\\sounddevice.py:909\u001b[0m, in \u001b[0;36m_StreamBase.__init__\u001b[1;34m(self, kind, samplerate, blocksize, device, channels, dtype, latency, extra_settings, callback, finished_callback, clip_off, dither_off, never_drop_input, prime_output_buffers_using_stream_callback, userdata, wrap_callback)\u001b[0m\n\u001b[0;32m    907\u001b[0m     userdata \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mNULL\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ptr \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPaStream**\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 909\u001b[0m \u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPa_OpenStream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msamplerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallback_ptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mError opening \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;66;03m# dereference PaStream** --> PaStream*\u001b[39;00m\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ptr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ptr[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Repo\\SIADs_Audio_Text_SRS\\env\\lib\\site-packages\\sounddevice.py:2796\u001b[0m, in \u001b[0;36m_check\u001b[1;34m(err, msg)\u001b[0m\n\u001b[0;32m   2793\u001b[0m     hosterror_info \u001b[38;5;241m=\u001b[39m host_api, info\u001b[38;5;241m.\u001b[39merrorCode, hosterror_text\n\u001b[0;32m   2794\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PortAudioError(errormsg, err, hosterror_info)\n\u001b[1;32m-> 2796\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m PortAudioError(errormsg, err)\n",
      "\u001b[1;31mPortAudioError\u001b[0m: Error opening InputStream: Invalid sample rate [PaErrorCode -9997]"
     ]
    }
   ],
   "source": [
    "from Extracted_Text import record_audio\n",
    "from Extracted_Text import wav_to_text_and_tokenize\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# file name \n",
    "filename = \"C:\\\\Repo\\\\SIADs_Audio_Text_SRS\\\\Datasets\\\\audio.wav\"\n",
    "\n",
    "# call the record_audio function to record audio from the microphone and save it to a file\n",
    "print(\"Recording audio...\")\n",
    "record_audio(filename)\n",
    "print(\"Recording finished.\")\n",
    "# call the extract_text_from_audio function to extract text from the audio file and save it to a file\n",
    "\n",
    "'''# call the wav_to_text_and_tokenize function to convert the audio file to text and tokenize it\n",
    "print(\"Converting audio to text...\")\n",
    "text = wav_to_text_and_tokenize(filename)\n",
    "print(text)\n",
    "print(\"Conversion finished.\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Repo\\SIADs_Audio_Text_SRS\\env\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "WARNING:root:Could not import librosa: No module named 'librosa'. Some functionality may be disabled.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'some_audio.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# file name \u001b[39;00m\n\u001b[0;32m     20\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRepo\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSIADs_Audio_Text_SRS\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDatasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124maudio.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m, in \u001b[0;36mvisualize\u001b[1;34m(filename, title)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvisualize\u001b[39m(filename, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Visualize the result of calling seg.filter_bank() for any number of filters\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     seg \u001b[38;5;241m=\u001b[39m \u001b[43maudiosegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msome_audio.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresample(sample_rate_Hz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24000\u001b[39m, sample_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m     spect, frequencies \u001b[38;5;241m=\u001b[39m seg\u001b[38;5;241m.\u001b[39mfilter_bank(nfilters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      9\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Repo\\SIADs_Audio_Text_SRS\\env\\lib\\site-packages\\audiosegment.py:1133\u001b[0m, in \u001b[0;36mfrom_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m   1131\u001b[0m _name, ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(path)\n\u001b[0;32m   1132\u001b[0m ext \u001b[38;5;241m=\u001b[39m ext\u001b[38;5;241m.\u001b[39mlower()[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m-> 1133\u001b[0m seg \u001b[38;5;241m=\u001b[39m \u001b[43mpydub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m AudioSegment(seg, path)\n",
      "File \u001b[1;32mc:\\Repo\\SIADs_Audio_Text_SRS\\env\\lib\\site-packages\\pydub\\audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[1;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 651\u001b[0m file, close_file \u001b[38;5;241m=\u001b[39m \u001b[43m_fd_or_path_or_tempfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m:\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Repo\\SIADs_Audio_Text_SRS\\env\\lib\\site-packages\\pydub\\utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[1;34m(fd, mode, tempfile)\u001b[0m\n\u001b[0;32m     57\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fd, basestring):\n\u001b[1;32m---> 60\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'some_audio.wav'"
     ]
    }
   ],
   "source": [
    "import audiosegment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize(filename, title=\"\"):\n",
    "    # Visualize the result of calling seg.filter_bank() for any number of filters\n",
    "    seg = audiosegment.from_file(\"some_audio.wav\").resample(sample_rate_Hz=24000, sample_width=2, channels=1)\n",
    "    spect, frequencies = seg.filter_bank(nfilters=5)\n",
    "    i = 0\n",
    "    for freq, (index, row) in zip(frequencies[::-1], enumerate(spect[::-1, :])):\n",
    "        plt.subplot(spect.shape[0], 1, index + 1)\n",
    "        if i == 0:\n",
    "            plt.title(title)\n",
    "            i += 1\n",
    "        plt.ylabel(\"{0:.0f}\".format(freq))\n",
    "        plt.plot(row)\n",
    "    plt.show()\n",
    "\n",
    "# file name \n",
    "filename = \"C:\\\\Repo\\\\SIADs_Audio_Text_SRS\\\\Datasets\\\\audio.wav\"\n",
    "visualize(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ODINO', 'MFR_NAME', 'MAKETXT', 'MODELTXT', 'YEARTXT', 'CRASH',\n",
      "       'FAILDATE', 'FIRE', 'INJURED', 'DEATHS', 'COMPDESC', 'CITY', 'STATE',\n",
      "       'VIN', 'DATEA', 'LDATE', 'MILES', 'OCCURENCES', 'CDESCR', 'CMPL_TYPE',\n",
      "       'POLICE_RPT_YN', 'PURCH_DT', 'ORIG_OWNER_YN', 'ANTI_BRAKES_YN',\n",
      "       'CRUISE_CONT_YN', 'NUM_CYLS', 'DRIVE_TRAIN', 'FUEL_SYS', 'FUEL_TYPE',\n",
      "       'TRANS_TYPE', 'VEH_SPEED', 'DOT', 'TIRE_SIZE', 'LOC_OF_TIRE',\n",
      "       'TIRE_FAIL_TYPE', 'ORIG_EQUIP_YN', 'MANUF_DT', 'SEAT_TYPE',\n",
      "       'RESTRAINT_TYPE', 'DEALER_NAME', 'DEALER_TEL', 'DEALER_CITY',\n",
      "       'DEALER_STATE', 'DEALER_ZIP', 'PROD_TYPE', 'REPAIRED_YN',\n",
      "       'MEDICAL_ATTN', 'VEHICLES_TOWED_YN', 'COMPDESC_StateEncoded',\n",
      "       'COMPDESC_CONDENSED', 'COMPDESC_CONDENSED_StateEncoded',\n",
      "       'CDESCR_CLEANED'],\n",
      "      dtype='object')\n",
      "51\n",
      "['VISIBILITY', 'SERVICE BRAKES, HYDRAULIC', 'TRAILER HITCHES', 'Tether, Lower Anchor (on car seat or vehicle)', 'SERVICE BRAKES, HYDRAULIC; AUTOHOLD BRAKE SYSTEM', 'VEHICLE SPEED CONTROL', 'WIPER', 'WHEELS', 'TIRES', 'FUEL SYSTEM, GASOLINE', 'Carry Handle, Shell, Base', 'ENGINE AND ENGINE COOLING', 'STEERING', 'LOCKS', 'PARKING BRAKE', 'LINKAGES', 'HYBRID PROPULSION SYSTEM', 'POWER TRAIN', 'FUEL SYSTEM, DIESEL', 'FUEL SYSTEM, OTHER', 'FORWARD COLLISION AVOIDANCE', 'Chest Clip, Buckle, Harness', 'ENGINE', 'Insert, Padding', 'SERVICE BRAKES', 'PROPULSION SYSTEM', 'INTERIOR LIGHTING', 'SEAT BELTS', 'BACK OVER PREVENTION', 'COMMUNICATION', 'NONE', 'CHILD SEAT', 'LANE DEPARTURE', 'EQUIPMENT', 'EXTERIOR LIGHTING', 'AIR BAGS', 'LATCHES', 'I am not sure ', 'BRAKE HOLD', 'FIRERELATED', 'ELECTRONIC STABILITY CONTROL (ESC)', 'STRUCTURE', 'ELECTRICAL SYSTEM', 'Other', 'FUEL', 'SUSPENSION', 'SERVICE BRAKES, ELECTRIC', 'SEATS', 'SERVICE BRAKES, AIR', 'UNKNOWN OR OTHER', 'TRACTION CONTROL SYSTEM']\n",
      "{'STRUCTURE:BODY': 'STRUCTURE', 'STEERING': 'STEERING', 'SERVICE BRAKES': 'SERVICE BRAKES', 'ELECTRICAL SYSTEM': 'ELECTRICAL SYSTEM', 'VEHICLE SPEED CONTROL': 'VEHICLE SPEED CONTROL', 'UNKNOWN OR OTHER': 'UNKNOWN OR OTHER', 'SUSPENSION': 'SUSPENSION', 'BACK OVER PREVENTION: SENSING SYSTEM: CAMERA': 'BACK OVER PREVENTION', 'ENGINE': 'ENGINE', 'VISIBILITY:REARVIEW MIRRORS/DEVICES:EXTERIOR': 'VISIBILITY', 'POWER TRAIN': 'POWER TRAIN', 'EXTERIOR LIGHTING': 'EXTERIOR LIGHTING', 'FUEL/PROPULSION SYSTEM': 'PROPULSION SYSTEM', 'AIR BAGS': 'AIR BAGS', 'FORWARD COLLISION AVOIDANCE: WARNINGS': 'FORWARD COLLISION AVOIDANCE', 'BACK OVER PREVENTION: REARVIEW SYSTEM BRAKING': 'BACK OVER PREVENTION', 'NONE': 'NONE', 'VISIBILITY:SUN/MOON ROOF ASSEMBLY': 'VISIBILITY', 'VISIBILITY/WIPER': 'WIPER', 'FORWARD COLLISION AVOIDANCE: AUTOMATIC EMERGENCY BRAKING': 'FORWARD COLLISION AVOIDANCE', 'FORWARD COLLISION AVOIDANCE: ADAPTIVE CRUISE CONTROL': 'FORWARD COLLISION AVOIDANCE', 'STRUCTURE': 'STRUCTURE', 'WHEELS': 'WHEELS', 'TIRES': 'TIRES', 'TIRES:SIDEWALL': 'TIRES', 'BACK OVER PREVENTION: WARNINGS': 'BACK OVER PREVENTION', 'SEATS': 'SEATS', 'Carry Handle, Shell, Base': 'Carry Handle, Shell, Base', 'FUEL SYSTEM, DIESEL': 'FUEL SYSTEM, DIESEL', 'VISIBILITY': 'VISIBILITY', 'FUEL SYSTEM, GASOLINE:DELIVERY:FUEL PUMP': 'FUEL SYSTEM, GASOLINE', 'FUEL SYSTEM, DIESEL:DELIVERY:FUEL PUMP': 'FUEL SYSTEM, DIESEL', 'ENGINE AND ENGINE COOLING': 'ENGINE AND ENGINE COOLING', 'SEAT BELTS': 'SEAT BELTS', 'LATCHES/LOCKS/LINKAGES:ELECTRONIC LOCK/LATCH ACTUATOR': 'LINKAGES', 'FORWARD COLLISION AVOIDANCE': 'FORWARD COLLISION AVOIDANCE', 'SERVICE BRAKES, HYDRAULIC': 'SERVICE BRAKES, HYDRAULIC', 'ENGINE AND ENGINE COOLING:ENGINE:DIESEL': 'ENGINE AND ENGINE COOLING', 'POWER TRAIN:AUTOMATIC TRANSMISSION:CONTROL MODULE (TCM/PCM/TECM)': 'POWER TRAIN', 'FUEL SYSTEM, GASOLINE': 'FUEL SYSTEM, GASOLINE', 'STRUCTURE:FRAME AND MEMBERS': 'STRUCTURE', 'EQUIPMENT:RECREATIONAL VEHICLE/TRAILER:PLUMBING:POTABLE WATER:STORAGE TANK': 'EQUIPMENT', 'LANE DEPARTURE: BLIND SPOT DETECTION': 'LANE DEPARTURE', 'LATCHES/LOCKS/LINKAGES': 'LINKAGES', 'CHILD SEAT': 'CHILD SEAT', 'EXTERIOR LIGHTING:HEADLIGHTS': 'EXTERIOR LIGHTING', 'LANE DEPARTURE: ASSIST': 'LANE DEPARTURE', 'BACK OVER PREVENTION': 'BACK OVER PREVENTION', 'ENGINE AND ENGINE COOLING:COOLING SYSTEM': 'ENGINE AND ENGINE COOLING', 'LATCHES/LOCKS/LINKAGES:HOOD:LATCH': 'LINKAGES', 'TIRES:PRESSURE MONITORING AND REGULATING SYSTEMS': 'TIRES', 'BACK OVER PREVENTION: AUTOMATIC SYSTEM BRAKING': 'BACK OVER PREVENTION', 'ELECTRICAL SYSTEM:12V/24V/48V BATTERY': 'ELECTRICAL SYSTEM', 'SEATS:FRONT ASSEMBLY:HEAD RESTRAINT': 'SEATS', 'POWER TRAIN:AUTOMATIC TRANSMISSION:TORQUE CONVERTER': 'POWER TRAIN', 'STEERING:ELECTRIC POWER ASSIST SYSTEM': 'STEERING', 'LATCHES/LOCKS/LINKAGES:DOORS:LATCH': 'LINKAGES', 'ELECTRICAL SYSTEM: INSTRUMENT CLUSTER/PANEL': 'ELECTRICAL SYSTEM', 'ENGINE AND ENGINE COOLING:EXHAUST SYSTEM:MANIFOLD/HEADER/MUFFLER/TAIL PIPE': 'ENGINE AND ENGINE COOLING', 'SERVICE BRAKES, HYDRAULIC:FOUNDATION COMPONENTS:DISC:ROTOR': 'SERVICE BRAKES, HYDRAULIC', 'STRUCTURE:BODY:DOOR ': 'STRUCTURE', 'POWER TRAIN:CLUTCH ASSEMBLY': 'POWER TRAIN', 'SERVICE BRAKES, ELECTRIC': 'SERVICE BRAKES, ELECTRIC', 'ELECTRICAL SYSTEM:ADAS:HILL DESCENT ASSIST:SOFTWARE': 'ELECTRICAL SYSTEM', 'VISIBILITY:POWER WINDOW DEVICES AND CONTROLS': 'VISIBILITY', 'Chest Clip, Buckle, Harness': 'Chest Clip, Buckle, Harness', 'FUEL SYSTEM, GASOLINE:STORAGE:EVAPORATIVE EMISSIONS:HOSES/VALVES/SENSORS': 'FUEL SYSTEM, GASOLINE', 'LANE DEPARTURE: WARNING': 'LANE DEPARTURE', 'SUSPENSION:FRONT:CONTROL ARM:LOWER BALL JOINT': 'SUSPENSION', 'VEHICLE SPEED CONTROL:ACCELERATOR PEDAL': 'VEHICLE SPEED CONTROL', 'TIRES:TREAD/BELT': 'TIRES', 'TIRES:TUBE': 'TIRES', 'EXTERIOR LIGHTING:HEADLIGHTS:BULBS': 'EXTERIOR LIGHTING', 'ELECTRONIC STABILITY CONTROL (ESC)': 'ELECTRONIC STABILITY CONTROL (ESC)', 'WHEELS:HUB': 'WHEELS', 'POWER TRAIN:TRANSFER CASE (4-WHEEL DRIVE)': 'POWER TRAIN', 'POWER TRAIN:DRIVELINE': 'POWER TRAIN', 'ENGINE AND ENGINE COOLING:COOLING SYSTEM:FAN': 'ENGINE AND ENGINE COOLING', 'EQUIPMENT': 'EQUIPMENT', 'EXTERIOR LIGHTING:TURN SIGNAL': 'EXTERIOR LIGHTING', 'VISIBILITY:WINDSHIELD': 'VISIBILITY', 'VISIBILITY:WINDSHIELD WIPER/WASHER:MOTOR': 'VISIBILITY', 'POWER TRAIN:AUTOMATIC TRANSMISSION': 'POWER TRAIN', 'VEHICLE SPEED CONTROL:CRUISE CONTROL': 'VEHICLE SPEED CONTROL', 'EXTERIOR LIGHTING:BRAKE LIGHTS': 'EXTERIOR LIGHTING', 'ENGINE AND ENGINE COOLING:EXHAUST SYSTEM': 'ENGINE AND ENGINE COOLING', 'Tether, Lower Anchor (on car seat or vehicle)': 'Tether, Lower Anchor (on car seat or vehicle)', 'FUEL SYSTEM, GASOLINE:DELIVERY:FUEL PUMP:CONTROL/DRIVE MODULE': 'FUEL SYSTEM, GASOLINE', 'TRACTION CONTROL SYSTEM': 'TRACTION CONTROL SYSTEM', 'ELECTRICAL SYSTEM:HORN': 'ELECTRICAL SYSTEM', 'STEERING:GEAR BOX (OTHER THAN RACK AND PINION)': 'STEERING', 'SUSPENSION:FRONT:STABILIZER BAR': 'SUSPENSION', 'SUSPENSION:FRONT:CONTROL ARM:LOWER ARM': 'SUSPENSION', 'ENGINE AND ENGINE COOLING:EXHAUST SYSTEM:EMISSION CONTROL ': 'ENGINE AND ENGINE COOLING', 'ELECTRICAL SYSTEM:IGNITION:COIL:SPARK PLUGS': 'ELECTRICAL SYSTEM', 'LANE DEPARTURE': 'LANE DEPARTURE', 'FUEL SYSTEM, DIESEL:STORAGE:TANK ASSEMBLY': 'FUEL SYSTEM, DIESEL', 'ELECTRICAL SYSTEM:ADAS': 'ELECTRICAL SYSTEM', 'STRUCTURE:BODY:HATCHBACK/LIFTGATE:SUPPORT DEVICE/STRUT': 'STRUCTURE', 'Other/I am not sure ': 'I am not sure ', 'STEERING:HYDRAULIC POWER ASSIST:POWER STEERING FLUID': 'STEERING', 'LATCHES/LOCKS/LINKAGES:DOORS:LATCH:EMERGENCY MECHANICAL RELEASE': 'LINKAGES', 'SERVICE BRAKES, HYDRAULIC:FLUID': 'SERVICE BRAKES, HYDRAULIC', 'ENGINE AND ENGINE COOLING:ENGINE:OIL/LUBRICATION: OIL COOLER': 'ENGINE AND ENGINE COOLING', 'STRUCTURE:BODY:TAILGATE ': 'STRUCTURE', 'STRUCTURE:BODY:ROOF AND PILLARS': 'STRUCTURE', 'PARKING BRAKE': 'PARKING BRAKE', 'LATCHES/LOCKS/LINKAGES:DOORS:LOCK': 'LINKAGES', 'ENGINE AND ENGINE COOLING:COOLING SYSTEM:PUMP': 'ENGINE AND ENGINE COOLING', 'ENGINE AND ENGINE COOLING:EXHAUST SYSTEM:EMISSION CONTROL:CATALYTIC CONVERTOR': 'ENGINE AND ENGINE COOLING', 'ENGINE AND ENGINE COOLING:ENGINE:CRANK/CAMSHAFT POSITION SENSOR': 'ENGINE AND ENGINE COOLING', 'ENGINE AND ENGINE COOLING:EXHAUST SYSTEM:EMISSION CONTROL:CRANKCASE (PCV)': 'ENGINE AND ENGINE COOLING', 'EXTERIOR LIGHTING:HEADLIGHTS:HIGH/LOW BEAM DIMMER SWITCH': 'EXTERIOR LIGHTING', 'POWER TRAIN:AUTOMATIC TRANSMISSION:INTERNAL:CLUTCHES/BANDS': 'POWER TRAIN', 'FUEL SYSTEM, GASOLINE:STORAGE:EVAPORATIVE EMISSIONS:CANISTER': 'FUEL SYSTEM, GASOLINE', 'EQUIPMENT:RECREATIONAL VEHICLE/TRAILER': 'EQUIPMENT', 'STRUCTURE:INTERIOR PANELS:DASHBOARD': 'STRUCTURE', 'EXTERIOR LIGHTING:TURN SIGNAL:SWITCH': 'EXTERIOR LIGHTING', 'ELECTRICAL SYSTEM:PROPULSION SYSTEM:TRACTION BATTERY': 'ELECTRICAL SYSTEM', 'VISIBILITY:REAR WINDOW WIPER/WASHER:LINKAGES': 'VISIBILITY', 'FORWARD COLLISION AVOIDANCE: SENSING SYSTEM: RADAR': 'FORWARD COLLISION AVOIDANCE', 'FUEL SYSTEM, GASOLINE:FUEL INJECTION SYSTEM': 'FUEL SYSTEM, GASOLINE', 'ELECTRICAL SYSTEM:ADAS:CONTROL MODULE': 'ELECTRICAL SYSTEM', 'VISIBILITY:DEFROSTER/DEFOGGER/HVAC SYSTEM': 'VISIBILITY', 'SEATS:FRONT ASSEMBLY:SEAT HEATER/COOLER': 'SEATS', 'FIRERELATED': 'FIRERELATED', 'COMMUNICATION: AUTO CRASH NOTIFICATION': 'COMMUNICATION', 'PARKING BRAKE:ELECTRICAL': 'PARKING BRAKE', 'STRUCTURE:BODY:DOOR:HINGE AND ATTACHMENTS': 'STRUCTURE', 'FUEL SYSTEM, GASOLINE:STORAGE:TANK ASSEMBLY:FILLER PIPE AND CAP': 'FUEL SYSTEM, GASOLINE', 'SEATS:FRONT ASSEMBLY:POWER ADJUST': 'SEATS', 'Insert, Padding': 'Insert, Padding', 'LATCHES/LOCKS/LINKAGES:TRUNK LID:LATCH:EMERGENCY MECHANICAL RELEASE': 'LINKAGES', 'AIR BAGS:PASSENGER SIDE FRONTAL:CUSHION': 'AIR BAGS', 'ELECTRICAL SYSTEM:PROPULSION SYSTEM': 'ELECTRICAL SYSTEM', 'SEATS:BARRIERS': 'SEATS', 'COMMUNICATION': 'COMMUNICATION', 'TRAILER HITCHES': 'TRAILER HITCHES', 'ENGINE AND ENGINE COOLING:ENGINE:OIL/LUBRICATION:PIPES, HOSES, AND FITTINGS': 'ENGINE AND ENGINE COOLING', 'POWER TRAIN:AXLE ASSEMBLY': 'POWER TRAIN', 'ELECTRICAL SYSTEM:STARTER ASSEMBLY': 'ELECTRICAL SYSTEM', 'HYBRID PROPULSION SYSTEM': 'HYBRID PROPULSION SYSTEM', 'VISIBILITY:GLASS, SIDE/REAR': 'VISIBILITY', 'LANE DEPARTURE: SENSING SYSTEM: RADAR': 'LANE DEPARTURE', 'AIR BAGS:SENSOR:OCCUPANT CLASSIFICATION': 'AIR BAGS', 'AIR BAGS:SENSOR:OCCUPANT CLASSIFICATION:FRONT PASSENGER': 'AIR BAGS', 'VISIBILITY:DEFROSTER/DEFOGGER/HVAC SYSTEM:REAR WINDOW': 'VISIBILITY', 'EQUIPMENT:ELECTRICAL:INFOTAINMENT:BLUETOOTH/WIFI': 'EQUIPMENT', 'ELECTRICAL SYSTEM:PROPULSION SYSTEM:CHARGING:CABLE/CORD:ACCESSORY': 'ELECTRICAL SYSTEM', 'STRUCTURE:BODY:HOOD': 'STRUCTURE', 'ELECTRICAL SYSTEM:ALTERNATOR/GENERATOR/REGULATOR': 'ELECTRICAL SYSTEM', 'ELECTRICAL SYSTEM:INSTRUMENT PANEL:SPEEDOMETER/ODOMETER:SENSOR/SENDING UNIT': 'ELECTRICAL SYSTEM', 'ELECTRICAL SYSTEM:IGNITION:ANTI-THEFT:IMMOBILIZER/PROXIMITY:KEY/SENDER': 'ELECTRICAL SYSTEM', 'SEATS:MID/REAR ASSEMBLY:HEAD RESTRAINT': 'SEATS', 'INTERIOR LIGHTING': 'INTERIOR LIGHTING', 'STEERING:RACK AND PINION': 'STEERING', 'LANE DEPARTURE: LANE KEEP: AUTOMATIC STEERING': 'LANE DEPARTURE', 'ELECTRICAL SYSTEM:ADAS:PARKING ASSIST:WARNING': 'ELECTRICAL SYSTEM', 'FUEL SYSTEM, GASOLINE:STORAGE:TANK ASSEMBLY': 'FUEL SYSTEM, GASOLINE', 'ELECTRICAL SYSTEM:SOFTWARE': 'ELECTRICAL SYSTEM', 'SEATS:CRITICAL FASTENERS': 'SEATS', 'ELECTRICAL SYSTEM:ADAS:AUTONOMOUS/SELF DRIVING': 'ELECTRICAL SYSTEM', 'ENGINE AND ENGINE COOLING:COOLING SYSTEM:RADIATOR ASSEMBLY': 'ENGINE AND ENGINE COOLING', 'VISIBILITY:REARVIEW MIRRORS/DEVICES': 'VISIBILITY', 'POWER TRAIN:DRIVELINE:DIFFERENTIAL UNIT': 'POWER TRAIN', 'ENGINE AND ENGINE COOLING:ENGINE:GASOLINE:TURBO/SUPERCHARGER': 'ENGINE AND ENGINE COOLING', 'EXTERIOR LIGHTING:TAIL LIGHTS': 'EXTERIOR LIGHTING', 'SUSPENSION:FRONT:CONTROL ARM': 'SUSPENSION', 'VEHICLE SPEED CONTROL:THROTTLE ': 'VEHICLE SPEED CONTROL', 'POWER TRAIN:AUTOMATIC TRANSMISSION:LEVER AND LINKAGE:COLUMN SHIFT': 'POWER TRAIN', 'ENGINE AND ENGINE COOLING:EXHAUST SYSTEM:EMISSION CONTROL:UREA INJECTION SYSTEM (DEF)': 'ENGINE AND ENGINE COOLING', 'STRUCTURE:BODY:HATCHBACK/LIFTGATE': 'STRUCTURE', 'TIRES:MARKINGS': 'TIRES', 'AIR BAGS:FRONTAL:DRIVER CLOCKSPRING/SPIRAL CASSETTE': 'AIR BAGS', 'CHILD SEAT:LATCH STRAP': 'CHILD SEAT', 'SEAT BELTS: REAR/OTHER:BUCKLE ASSEMBLY': 'SEAT BELTS', 'SERVICE BRAKES, HYDRAULIC:FOUNDATION COMPONENTS:MASTER CYLINDER': 'SERVICE BRAKES, HYDRAULIC', 'STRUCTURE:INTERIOR PANELS:SUN VISOR': 'STRUCTURE', 'ENGINE AND ENGINE COOLING:ENGINE:OTHER FUEL TYPES:TURBO/SUPERCHARGER:INTERCOOLER': 'ENGINE AND ENGINE COOLING', 'EXTERIOR LIGHTING:BACK UP LIGHTS:BULBS': 'EXTERIOR LIGHTING', 'ELECTRICAL SYSTEM:IGNITION:ANTI-THEFT:CONTROL MODULE': 'ELECTRICAL SYSTEM', 'STEERING:COLUMN LOCKING:ANTI-THEFT DEVICE': 'STEERING', 'ELECTRICAL SYSTEM:INSTRUMENT PANEL:SPEEDOMETER/ODOMETER': 'ELECTRICAL SYSTEM', 'STEERING:COLUMN': 'STEERING', 'FUEL SYSTEM, GASOLINE:FUEL INJECTION SYSTEM:INJECTORS': 'FUEL SYSTEM, GASOLINE', 'POWER TRAIN:DRIVELINE:DRIVESHAFT': 'POWER TRAIN', 'FUEL SYSTEM, GASOLINE:FUEL INJECTION SYSTEM:THROTTLEBODY/MANIFOLD': 'FUEL SYSTEM, GASOLINE', 'LATCHES/LOCKS/LINKAGES:FUELING/CHARGING DOOR/HATCH/PORT': 'LINKAGES', 'EQUIPMENT:ELECTRICAL:INFOTAINMENT:VIDEO (TOUCH)SCREEN/MONITOR/UNIT': 'EQUIPMENT', 'LATCHES/LOCKS/LINKAGES:TAILGATE:LATCH': 'LINKAGES', 'POWER TRAIN:AUTOMATIC TRANSMISSION:GEAR POSITION INDICATION (PRNDL)': 'POWER TRAIN', 'ELECTRICAL SYSTEM:BODY CONTROL MODULE/BCM': 'ELECTRICAL SYSTEM', 'CHILD SEAT:HARNESS RETAINER/CHEST CLIP ': 'CHILD SEAT', 'ELECTRONIC STABILITY CONTROL (ESC):CONTROL MODULE': 'ELECTRONIC STABILITY CONTROL (ESC)', 'FUEL SYSTEM, OTHER': 'FUEL SYSTEM, OTHER', 'ENGINE AND ENGINE COOLING:ENGINE:ENGINE CONTROL MODULE (ECU/ECM)': 'ENGINE AND ENGINE COOLING', 'ELECTRICAL SYSTEM:INSTRUMENT PANEL:FUEL GAUGE': 'ELECTRICAL SYSTEM', 'AIR BAGS:SRS MALFUNCTION WARNING LAMP/LIGHT': 'AIR BAGS', 'EQUIPMENT:ELECTRICAL:ACCESSORY GENERATOR': 'EQUIPMENT', 'VISIBILITY:REARVIEW MIRRORS/DEVICES:INTERIOR': 'VISIBILITY', 'STRUCTURE:BODY:TRUNK LID ': 'STRUCTURE', 'LATCHES/LOCKS/LINKAGES:TRUNK LID:LATCH': 'LINKAGES', 'ENGINE AND ENGINE COOLING:ENGINE:GASOLINE:BELTS AND ASSOCIATED PULLEYS': 'ENGINE AND ENGINE COOLING', 'SERVICE BRAKES, HYDRAULIC; AUTOHOLD BRAKE SYSTEM/BRAKE HOLD:SOFTWARE': 'BRAKE HOLD', 'ELECTRICAL SYSTEM: INTEGRATED TRAILER BRAKE CONTROL': 'ELECTRICAL SYSTEM', 'POWER TRAIN:AUTOMATIC TRANSMISSION:INTERNAL:GEARS': 'POWER TRAIN', 'VISIBILITY:DEFROSTER/DEFOGGER/HVAC SYSTEM:CONDENSOR/EVAPORATOR': 'VISIBILITY', 'ELECTRICAL SYSTEM:PROPULSION SYSTEM:CHARGING:MODULE:ONBOARD (OBCM)': 'ELECTRICAL SYSTEM', 'ELECTRICAL SYSTEM:IGNITION': 'ELECTRICAL SYSTEM', 'STEERING:LINKAGES:TIE ROD ASSEMBLY': 'STEERING', 'ELECTRICAL SYSTEM:ADAS:AUTONOMOUS/SELF DRIVING:SOFTWARE': 'ELECTRICAL SYSTEM', 'ELECTRICAL SYSTEM:IGNITION:COIL': 'ELECTRICAL SYSTEM', 'AIR BAGS:FRONTAL:DRIVER SIDE:CUSHION': 'AIR BAGS', 'SERVICE BRAKES, AIR:ANTILOCK:ABS WARNING LIGHT': 'SERVICE BRAKES, AIR', 'SERVICE BRAKES, HYDRAULIC:ANTILOCK/TRACTION CONTROL/ELECTRONIC LIMITED SLIP:WHEEL SPEED SENSOR': 'SERVICE BRAKES, HYDRAULIC', 'VISIBILITY:FIXED PANARAMIC ROOF/SKY LIGHT ASSEMBLY': 'VISIBILITY', 'ENGINE AND ENGINE COOLING:ENGINE:OIL/LUBRICATION:PRESSURE/TEMPERATURE SENSOR': 'ENGINE AND ENGINE COOLING', 'SERVICE BRAKES, HYDRAULIC:FOUNDATION COMPONENTS:DISC:PADS ': 'SERVICE BRAKES, HYDRAULIC', 'EQUIPMENT:MECHANICAL:ACCESSORY SCISSOR/SCREW/BOTTLE JACK/LIFT': 'EQUIPMENT', 'LATCHES/LOCKS/LINKAGES:HATCHBACK/LIFTGATE:LOCK': 'LINKAGES', 'STRUCTURE:BODY:BUMPERS': 'STRUCTURE', 'FUEL SYSTEM, GASOLINE:STORAGE:AUXILLARY TANK': 'FUEL SYSTEM, GASOLINE', 'SERVICE BRAKES, AIR:ANTILOCK:WHEEL SPEED SENSOR': 'SERVICE BRAKES, AIR', 'STEERING:STEERING WHEEL /HANDLE BAR:HAND HEATER/COOLER': 'STEERING', 'BACK OVER PREVENTION:DISPLAY FUNCTION': 'BACK OVER PREVENTION', 'FUEL SYSTEM, GASOLINE:FUEL INJECTION SYSTEM:MASS AIR FLOW (MAF) SENSOR': 'FUEL SYSTEM, GASOLINE'}\n",
      "a\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPDESC</th>\n",
       "      <th>COMPDESC_CONDENSED</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2051723</th>\n",
       "      <td>STRUCTURE:BODY</td>\n",
       "      <td>STRUCTURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051724</th>\n",
       "      <td>STEERING</td>\n",
       "      <td>STEERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051725</th>\n",
       "      <td>SERVICE BRAKES</td>\n",
       "      <td>SERVICE BRAKES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051726</th>\n",
       "      <td>ELECTRICAL SYSTEM</td>\n",
       "      <td>ELECTRICAL SYSTEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051727</th>\n",
       "      <td>VEHICLE SPEED CONTROL</td>\n",
       "      <td>VEHICLE SPEED CONTROL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066606</th>\n",
       "      <td>FUEL/PROPULSION SYSTEM</td>\n",
       "      <td>PROPULSION SYSTEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066607</th>\n",
       "      <td>UNKNOWN OR OTHER</td>\n",
       "      <td>UNKNOWN OR OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066608</th>\n",
       "      <td>UNKNOWN OR OTHER</td>\n",
       "      <td>UNKNOWN OR OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066609</th>\n",
       "      <td>STEERING</td>\n",
       "      <td>STEERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066610</th>\n",
       "      <td>AIR BAGS</td>\n",
       "      <td>AIR BAGS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14887 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       COMPDESC     COMPDESC_CONDENSED\n",
       "0                                                     \n",
       "2051723          STRUCTURE:BODY              STRUCTURE\n",
       "2051724                STEERING               STEERING\n",
       "2051725          SERVICE BRAKES         SERVICE BRAKES\n",
       "2051726       ELECTRICAL SYSTEM      ELECTRICAL SYSTEM\n",
       "2051727   VEHICLE SPEED CONTROL  VEHICLE SPEED CONTROL\n",
       "...                         ...                    ...\n",
       "2066606  FUEL/PROPULSION SYSTEM      PROPULSION SYSTEM\n",
       "2066607        UNKNOWN OR OTHER       UNKNOWN OR OTHER\n",
       "2066608        UNKNOWN OR OTHER       UNKNOWN OR OTHER\n",
       "2066609                STEERING               STEERING\n",
       "2066610                AIR BAGS               AIR BAGS\n",
       "\n",
       "[14887 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "STEERING\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# unpickle CDESCR_df.pkl to a dataframe\n",
    "with open(\"C:\\\\Repo\\\\SIADs_Audio_Text_SRS\\\\Datasets\\\\CDESCR_df.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# print all the column names in the dataframe\n",
    "print(df.columns)\n",
    "def condense_component_description(df, column_name):\n",
    "    \"\"\"\n",
    "    Condense the component description in the dataframe by removing any text after a colon or slash\n",
    "    \"\"\"\n",
    "    # get the unique values in the column\n",
    "    compdesc_list = df[column_name].unique()\n",
    "\n",
    "    # condense the compdesc_list with common text like the main text using regex like ELECTRICAL SYSTEM, there are multiple instances of this in the list with : separators and other text\n",
    "    compdesc_list_condensed = []\n",
    "    compdesc_dict = {}\n",
    "\n",
    "    # loop through the compdesc_list and check to see if there is a : or / in the text\n",
    "    for text in compdesc_list:\n",
    "        # check to see if ther is a : in the text\n",
    "        if \":\" in text:\n",
    "            # split the words on the : and / separator and then loop through the words\n",
    "            temp = text.split(\":\")[0]\n",
    "            words = temp.split(r'/')\n",
    "            # loop through the temp list and append the words to the compdesc_list_condensed list\n",
    "            for word in words:\n",
    "                # check to see if the word is not empty and not a number\n",
    "                compdesc_list_condensed.append(word)\n",
    "                compdesc_dict[text] = word\n",
    "        elif r'/' in text:\n",
    "            # split the words on the : and / separator and then loop through the words\n",
    "            words = text.split(r'/')\n",
    "            # loop through the temp list and append the words to the compdesc_list_condensed list\n",
    "            for word in words:\n",
    "                # check to see if the word is not empty and not a number\n",
    "                compdesc_list_condensed.append(word)\n",
    "                compdesc_dict[text] = word\n",
    "        else:\n",
    "            # append the text to the list\n",
    "            compdesc_list_condensed.append(text)\n",
    "            compdesc_dict[text] = text\n",
    "\n",
    "    # remove duplicates from the list\n",
    "    compdesc_list_condensed = list(set(compdesc_list_condensed))\n",
    "    \n",
    "    # return the condensed list and the dictionary\n",
    "    return compdesc_list_condensed, compdesc_dict\n",
    "\n",
    "# call the condense_component_description function to condense the component description in the dataframe by removing any text after a colon or slash\n",
    "compdesc_list_condensed, compdesc_dict = condense_component_description(df, \"COMPDESC\")\n",
    "\n",
    "print(len(compdesc_list_condensed))\n",
    "#print(len(compdesc_dict))\n",
    "print(compdesc_list_condensed)\n",
    "print(compdesc_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_keys_from_value(dictionary, target_value):\n",
    "    for key, value in dictionary.items():\n",
    "        # check to see if the value is a string and if it contains the target_value\n",
    "        if isinstance(value, str):\n",
    "            if value in target_value:\n",
    "                return key\n",
    "        else:\n",
    "            # check to see if the value is a number and if it is equal to the target_value\n",
    "            if target_value == value:\n",
    "                return key\n",
    "            else:\n",
    "                pass\n",
    "        return target_value\n",
    "\n",
    "my_dict = {'a': \"1\", 'b': 2, 'c': 1, 'd': 3}\n",
    "target = \"1\"\n",
    "result = get_keys_from_value(my_dict, target)\n",
    "print(result) # Output: ['a', 'c']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# use the compdesc_dict to look up \"COMPDESC\" against the keys of the dict and assign the value to a new column in the dataframe called \"COMPDESC_CONDENSED\"\n",
    "df[\"COMPDESC_CONDENSED\"] = df[\"COMPDESC\"].apply(lambda x: compdesc_dict.get(x))\n",
    "    #compdesc_dict)\n",
    "# display the dataframe with \"COMPDESC\" and \"COMPDESC_CONDENSED\" columns\n",
    "display(df[[\"COMPDESC\", \"COMPDESC_CONDENSED\"]])\n",
    "print(len(df[\"COMPDESC_CONDENSED\"].unique()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# find STRUCTURE:BODY in compdesc_dict\n",
    "print(get_keys_from_value(compdesc_dict, \"STEERING\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
