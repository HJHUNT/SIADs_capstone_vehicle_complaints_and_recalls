# Final Report

# **Why/ Background:**

When a vehicle owner has an issue with their automobile, they can drive it to or have it towed to a service shop to have it evaluated. This can be a dreadful experience for an owner, because more than likely they will have to pay out of pocket to take corrective actions to the given problem. If the service shop is affiliated with a manufacturer they may check to see if there are any recalls on the vehicle which could be related to the experienced issue. This would mean that some or all the repairs could be done by the manufacture under the recall. Savvy owners can try to find information about their vehicle prior to bringing it in, or even experiencing the issue, but this is limited to the given vehicles year, make, and model (2024 Ford F150 for example). This could be through a google search or going to the National Highway Traffic Safety Administration website (NHTSA). However, from these sources, a vehicle’s common issue experienced by other vehicles is not easily searchable. Thus, an information retrieval system for common issues across all vehicles would be very helpful for understanding if other recalls have been issued for the same experienced problem, as this could mean the difference of someone having to pay for the work or if the issue could be eventually elevated to a recall by the given manufacture (where the owner would not have to pay). With there being approximately 283.4 million vehicles registered in the United States there are a lot of different vehicle types with many perspectives at play, where searching for common issues should not be so narrow as it is (only by Make Model Year). There is a lot of untapped information about issues on vehicles and how to remediate them when changing perspectives.

The desire for exposing issues is not only something that is of interest to a vehicle owner for researching if their problem is something they will have to pay out of pocket for (complaints) or if others will have to pay (recalls). There is also a huge benefit for abstracting the issues for search for common problems from an enterprise perspective for Manufactures and Dealerships. Where there is a huge desire to limit or eliminate recalls, because each one can cost millions if not billions, so being proactive is critical to staying profitable. There are lessons to be learned from common problems that other manufacturers experience which can help drive prioritizing issue resolution, so strong products are shipped to commerce, as recalls cost a lot of money. With all of these interests at play this was the driving factor behind developing this project.

# Context

Here are some articles which inspired certain parts of our project. They helped guide processing flow and understanding what methods and or models could be used to make a robust information retrieval system and machine learning models.

- **NLP-based complaint resolution on automotive manufacturing data** [1]. This article gave us good ideas on text processing methods and IR recommendation methods through cosine similarity.
- **Training BERT for Similarity [2].** This gave us good idea on how to work with transformer architecture to develop IR systems.
- **Mastering Text Clustering with Python: A Comprehensive Guide [3].** This document gave good guidance on steps for processing text using NLTK for use in a clustering model.

# How/**Project statement:**

To help users find common issues across vehicles, an **information retrieval system** was built for retrieving documents on extracted text from complaints and recall documents from NHTSA. A logistic regression **classification model** is also implemented to help users determine whether their queried issue is more aligned towards complaints or recalls. Classification models are also used to predict which clustering a user's query identifies as a **specific component inside the vehicle** (e.g. power train), helping users determine the potential root cause of a vehicle issue. All of the models and methods were wrapped into a **lightweight user interface** constructed to show the information retrieval system, complaint/recall predictions from logistic regression model, and classification models, allowing for a quick and easy way to reveal common related issues and learn how they were resolved if they were recalls. Allowing to identify the root cause of vehicle issue to help users better understand a given issue from an abstracted perspective from the typical year, make, and model which can be extremely limiting.

# **Methodology:**

With a complex dataset there are a lot of components to the data sets, so extensive data exploration was done to better understand the data. The appendix can be referenced from some of the visualizations that were generated to better understand the data. Figure 1, shows the program flow of how user queries and the reference data is extracted, tokenized, and vectorized so it can be used in the perspective models and methods. Which the below sections go into details how these raw inputs are processed and the program yields meaningful information. 

![Figure 1: Program Flow Diagram](image.png)

Figure 1: Program Flow Diagram

## Dataset Description

As seen in the above flow diagram, two datasets, Recall.txt and Complaint.txt, are inputted for analysis.  The two datasets have been combined using vertical concatenation to produce a 72-column dataset. Here are some important columns which were used:

| Field Name | Source Table | Description |
| --- | --- | --- |
| RECORD_ID | RECALL | Running sequence number, uniquely identifies recall |
| MAKETXT | RECALL/COMPLAINT | Vehicle/equipment make |
| MODELTXT | RECALL/COMPLAINT | Vehicle/equipment model |
| YEARTXT | RECALL/COMPLAINT | Model year, 9999 if unknown or N/A |
| CDESCR | RECALL/COMPLAINT | Description of Issue. This column does not originally exist in Recall, so for Recall dataset, CDESCR is a string concatenation of DESC_DEFECT and CONSEQUENCE_DEFECT delimited by carriage return |
| COMPDESC | RECALL/COMPLAINT | Component description. Originally named COMPNAME  in Recall Dataset. **Used for Component Clustering Prediction.** |
| DESC_DEFECT | RECALL | Defect summary |
| CONSEQUENCE_DEFECT | RECALL | Consequence summary |
| CORRECTIVE_ACTION | RECALL | Corrective summary |

You can see the full field specification in the appendix, or refer to the official NHTSA documentation for original table field descriptions (for Recall.txt [4] and Complaint.txt [5])

## Data Modeling:

Different data models are built for each downstream ML task, with difference uniqueness levels.

**Information Retrieval, Complaint/Recall Classification Logistic Regression Data Model:** 

**Final Dataset Size:** 37423 rows, containing unique issue descriptions only (unique CDESCR)

**Vehicle Component Classification Clustering Data Model:** 

**Final Dataset Size:** 604584 rows, containing unique issue description + vehicle component only (unique CDESCR, COMPDESC)

## Data Extraction

Text is extracted from NHTSA complaints and recall documents to build information retrieval documents, logistic regression model for complaints/recall classification. Tokenizers and TfIdfVectorizers were applied on text to transform text into vectorizers, while stopword filters and stemmers were applied to remove irrelevant terms and improve downstream ML models.

![Stopwords Descri](image%201.png)

Figure 2: Sample text cleaning. Cleaned column is in A_CLEANED. Nltk stopwords removal, stemming using nltk PorterStemmer. 

## Downstream Machine Learning Tasks

A streamlit dashboard was built to compare ML model results.  

### User Interface for Inputting Queries

This project yielded software that can be run locally using a Stream lit server frontend that hosts a website style user interface, that allows the users to interact by inputs as complaints and or issues in the form of a query. It accepts written text (see Figure 2) or voice recordings (see Figure 3). The program is executed by pressing the “search and classifying” button, which takes the query and performs cosine similarity document retrieval system, a prediction with a logistic regression model, and predictions with classification models. 

![Figure 3: Entering a Text Query.](a98a4af0-cd95-4e86-adad-9115510a8973.png)

Figure 3: Entering a Text Query.

![Figure 4: Recording a Query which is converted to text for the user.](image%202.png)

Figure 4: Recording a Query which is converted to text for the user.

### Information Retrieval System

Information retrieval system with basic language interpretation takes in user query as input (shown above) and outputs suggestions (ex. User asks about a vehicle problem and the information retrieval system returns recall/complaint entries related to the problem).

The information retrieval system defines the string concatenation of “CONSEQUENCE_DEFECT” (Consequence Summary) and “DESC_DEFECT” (Defect Summary) columns from recall to define documents, and the ”CDESCR” (Description of the Complaint) column from complaint, so both complaint and recall datasets roughly describe vehicle issues. Columns like “CORRECTIVE_ACTION” (Corrective Summary) and “NOTES” (Recall Notes) were not string concatenated to the document, because the “CORRECTIVE_ACTION” (Corrective Summary)  mostly only describes solutions which repeat issue information and manufacture method of communication with vehicle owners, while “NOTES” (Recall Notes) mostly just link to NHTSA hotline. 

![Figure 5: <a href=”Exploration\dataset_exploration_vehicle_recall.ipynb”>Exploration\dataset_exploration_vehicle_recall.ipynb<a/>](image%203.png)

Figure 5: <a href=”Exploration\dataset_exploration_vehicle_recall.ipynb”>Exploration\dataset_exploration_vehicle_recall.ipynb<a/>

![Figure 6: <a href=”Exploration\dataset_exploration_vehicle_recall.ipynb”>Exploration\dataset_exploration_vehicle_recall.ipynb<a/>](image%204.png)

Figure 6: <a href=”Exploration\dataset_exploration_vehicle_recall.ipynb”>Exploration\dataset_exploration_vehicle_recall.ipynb<a/>

The user selects the desired number of documents to be returned by the program. The query is then processed (tokenized, vectorized, and dimensionality reduction) so cosine similarity can be run on the text to perform information retrieval. The "NHTSAs ID", "MANUFACTURER", "MAKE", "MODEL", "YEAR", "COMPONENT DESCRIPTION","ISSUE TYPE", "DESCRIPTION" are provided to reference the recommendations, see Figure 4 as a reference.

[](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEgAAABICAYAAABV7bNHAAAA1ElEQVR4Ae3bMQ4BURSFYY2xBuwQ7BIkTGxFRj9Oo9RdkXn5TvL3L19u+2ZmZmZmZhVbpH26pFcaJ9IrndMudb/CWadHGiden1bll9MIzqd79SUd0thY20qga4NA50qgoUGgoRJo/NL/V/N+QIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIEyFeEZyXQpUGgUyXQrkGgTSVQl/qGcG5pnkq3Sn0jOMv0k3Vpm05pmNjfsGPalFyOmZmZmdkbSS9cKbtzhxMAAAAASUVORK5CYII=)

![Figure 7: Cosine Similarity Information Retrieval Returned Documents](image%205.png)

Figure 7: Cosine Similarity Information Retrieval Returned Documents

### Vehicle Complaint/Recall Classification (Logistic Regression)

The complaint/recall classifier identifies whether a user’s queries issue is a complaint or recall. The logistic regression uses ”CDESCR” (Description of the Complaint) column from complaint dataset and “CONSEQUENCE_DEFECT” (Consequence Summary), “COMPDESC” (Specific Components Description) column from recall dataset. The columns were chosen to remove as many words as possible that are believed to have no contribution to the classification. The evaluation section has a further explanation of the rationale behind the choice of columns and what was removed to prevent data leakage. Figure 5 shows the visualization generated to show the probability of both the complaint and the recall.  

![Figure 8: Logistic Regression Probability of a Complaint or Recall](image%206.png)

Figure 8: Logistic Regression Probability of a Complaint or Recall

### Component Classification (Clustering)

The program has two deployed classification models: Random Forest and K-means. Spot checks indicate that the Random Forest classifier, trained on labeled component descriptions, more predictably identifies the component group for a given query. In contrast, the unsupervised K-means model, lacking labeled training data, produces component clusters that are less clearly defined. This blending of component groups in K-means makes direct reassociation with specific component groups challenging during prediction. Consequently, the Random Forest model serves as the default classifier, offering a more intuitive prediction of the component description. While K-means yields groups with multiple associated components, the description of the component with the highest frequency within the group is provided to indicate the dominant influencing factors.

A scatter plot was generated to help visualize what the clustering models are doing. The vectorized text was processed with a PCA dimensionality reductions to get them down to a 2-dimensional plane so they could be plotted on a vector space graph. The blue point in the scatter plot represents the user entered query. The orange points represent the user desired amount of most similar complaints from cosine similarity. The green points represent the model's prediction of which cluster the query is associated with. The different shades of grey represent the cluster groups and or component groups of other documents that are not associated with the predicted cluster. Tooltips have been enabled to allow the user to interact with the scatter plots, so the user can hover over the points and information will appear about a given document. Figure 6 shows the Random Forest Classifier vector space graph and Figure 7 shows the Kmeans Classifier vector space graph.

![Figure 9: Vector Space Scatter Plot of Random Forest Classifier with its prediction and Cosine Similarity Documents0](image%207.png)

Figure 9: Vector Space Scatter Plot of Random Forest Classifier with its prediction and Cosine Similarity Documents0

![Figure 10: Vector Space Scatter Plot of Kmeans Classifier with its prediction and Cosine Similarity Documents, Tooltip hover over can be seen as well.](image%208.png)

Figure 10: Vector Space Scatter Plot of Kmeans Classifier with its prediction and Cosine Similarity Documents, Tooltip hover over can be seen as well.

# **Evaluation strategy**

## Information Retrieval System

[Experimentation Code Here](Experiments/dense_retrieval.ipynb)

Information retrieval was tested using manual evaluation. Overall, it was found All-MiniLM-l6-v2 Transformer Information Retrieval has bias for exact keyword matches and short sentence length matches, so TruncatedSVD was chosen to be used as the information retrieval model. Appendix I offers some query examples to compare top results from both IR systems. 

## Logistic Regression

[Experimentation Code Here](Experiments/logistic_regression.ipynb)

The vehicle complaint/recall logistic regression model was evaluated using Precision, Recall, and ROC-AUC Score. The dataset is processed with 80-10-10 train test split. Here are the metrics on test set:

| **Label** | **Precision** | **Recall** | **F1-Score** | **Support** |
| --- | --- | --- | --- | --- |
| 0 | 1.00 | 0.94 | 0.97 | 1168 |
| 1 | 0.97 | 1.00 | 0.99 | 2567 |
| macro_avg | 0.99 | 0.97 | 0.98 | 3735 |

![Figure 11: Confusion Matrix Performance of Final Logistic Regression Model](image%209.png)

Figure 11: Confusion Matrix Performance of Final Logistic Regression Model

![Figure 12: ROC-AUC Performance of Final Logistic Regression Model](image%2010.png)

Figure 12: ROC-AUC Performance of Final Logistic Regression Model

As discussed in methodology section, we will discuss the rationale for our choice of columns to reduce data leakage.

### Initial Experimentation — What Didn’t Work

Initially, the idea was to just use ”CDESCR” (Description of the Complaint) column in complaint dataset and CONSEQUENCE_DEFECT” (Consequence Summary) and “DESC_DEFECT” (Defect Summary) columns in recall dataset (same columns used in information retrieval system) to build complaint/recall logistic regression model. However, this proved to be futile, as from analyzing feature importance, it was realized CONSEQUENCE_DEFECT” (Consequence Summary) in complaint dataset were not good columns for issue classification. The reason being that the logistic regression model was capturing either stopwords/the nature of language from these columns rather than issue descriptions. Looking at the feature importance plot below, it’s clear that the logistic regression model is using irrelevant words to predict complaint/recall, even after removing obvious stopwords like “recall”.

![Figure 13. Experiment 2 in [Experiments\logistic_regression.ipynb](Experiments\logistic_regression.ipynb)](image%2011.png)

Figure 13. Experiment 2 in [Experiments\logistic_regression.ipynb](Experiments\logistic_regression.ipynb)

![Figure 14. Experiment 2 in [Experiments\logistic_regression.ipynb](Experiments\logistic_regression.ipynb)](image%2012.png)

Figure 14. Experiment 2 in [Experiments\logistic_regression.ipynb](Experiments\logistic_regression.ipynb)

The colloquial language of complaints dataset and professional, specific details from recall dataset (e.g. vehicle class information) to discriminate between complaint and recall. 

These features are not what are desired traits for the model to learn. Changing TF-IDF hyperparameters such as max document frequency (reduce max_df=0.7 from to max_df=0.01) in hopes to block the model from using the nature of language proved to be ineffective as predictions learned from specific vehicle recall numbers (e.g. 23v858000, 24v608000) and vehicle class information (e.g. mbusa, 208, 121).

![Figure 15. Experiment 4 in [Experiments\logistic_regression.ipynb](Experiments\logistic_regression.ipynb)](image%2013.png)

Figure 15. Experiment 4 in [Experiments\logistic_regression.ipynb](Experiments\logistic_regression.ipynb)

![Figure 16. Experiment 4 in [Experiments\logistic_regression.ipynb](Experiments\logistic_regression.ipynb)](image%2014.png)

Figure 16. Experiment 4 in [Experiments\logistic_regression.ipynb](Experiments\logistic_regression.ipynb)

### **What Worked in the End**

Using the in-house method [OOP experimentation framework](Experiments/[classifier.py](http://classifier.py/)), allowed for rapid iteration on different column combinations and hyperparameters. After realizing the logistic regression algorithm is learning from the nature of language, it was decided to use different dataset columns to discriminate between complaints and recalls: CDESCR” (Description of the Complaint) column from complaint dataset and “CONSEQUENCE_DEFECT” (Consequence Summary), “COMPDESC” (Specific Components Description) column from recall dataset, removing “DESC_DEFECT” (Defect Summary) column entirely from the logistic regression equation.  These fields were believed to capture the nature of the issue better and decided to stick with them for the final iteration of the logistic regression model. 

Here is the feature importance plot for our final trained logistic regression model, as well as final hyperparameter settings.

```json
## Tf-Idf Vectorizer Parameters
{
    "ngram_range": [
        1,
        2
    ],
    "min_df": 20,
    "max_df": 0.7,
    "binary": true
}
## Logistic Regression Parameters
{
		"random_state" : 42,
    "loss" : "log_loss"
}
```

![Figure 17. Final Feature Importance — Experiment 5 in [Experiments\logistic_regression.ipynb]. Still some irrelevant words such as “cause” as top recall predictors but seeing much better prediction vocabulary such as fire, cooling, electric system.  ](image%2015.png)

Figure 17. Final Feature Importance — Experiment 5 in [Experiments\logistic_regression.ipynb]. Still some irrelevant words such as “cause” as top recall predictors but seeing much better prediction vocabulary such as fire, cooling, electric system.  

![Figure 18. Final Feature Importance — Experiment 5 in [Experiments\logistic_regression.ipynb]. Model is stilll learning some irrelevant words from the nature of language, such as caused, working, time, or manufacturer, but seeing much better prediction vocabulary such as oil, light, miles.](image%2016.png)

Figure 18. Final Feature Importance — Experiment 5 in [Experiments\logistic_regression.ipynb]. Model is stilll learning some irrelevant words from the nature of language, such as caused, working, time, or manufacturer, but seeing much better prediction vocabulary such as oil, light, miles.

## Component Classification Model

Silhouette Scores were calculated to help identify performance of the clustering methods, which ended up not definitively showing how well the program was working. One of the best evaluation methods was performing spot checks, enter a query and see if the results make sense. Spot checking of the outputs was done in parallel to traditional calculated values, but pointed to decent performance. 

# **Technical depth:**

The majority of the MADS course work has prepared us for this project, as this project has facets of data mining for text extraction/ vectorization/ dimensionality reduction, machine learning to create models based off the extracted text, information retrieval where multiple subclasses were tied together to build cohesive programs that take user inputs and provide meaningful outputs.

# **Broader impacts:**

Here are people who will be impacted by our work:

- Insurance Employees looking to determine whether a customer-sent entry is likely to lead to a recall or complaint.
- Normal vehicle owners looking for complaints/recalls similar to their vehicle problems, to decide whether they or manufacturers have to pay for issue.
- Dealership understanding issues arising from installed features at their shops.
- Manufacturers looking to remediate vehicle issues from the supply chain.

# Ethical Issues:

- Bias towards making recommendations for text with specific style of language. Words skewing the search.
- Misclassification of issues could lead to exaggeration/underestimation of vehicle problems queried from the user, resulting in harmful recommendations or over exaggeration of severity.
- Possible bias towards historically prevalent issues, bias towards US government perspective on vehicle complaints/recalls.
- Some vehicles and brands are not represented in the data set, so the machine learning models may not be able to generalize to overly specific vehicle information.

## Prospective Next Steps:

With this program being locally ran the next step would be to deploy it to a cloud service and or to a dedicated server connected to the web, to let many users interact with it. The data is also currently statically sourced on a manual base, where an automated polling method to the NHTSA API should be used to account for new data to be fed into the system. The models would also need to be retrained and or updated to include the newly added data on a periodic schedule.

# **Statement of Work:**

Hai Ran (Harris) Zheng: 

- Performed data exploration on text data and evaluating which columns would be useful for downstream ML tasks such as logistic regression and information retrieval.
- Prepared dataset and data models combining vehicle complaint and recall dataset, exploring levels of uniqueness on both datasets to determine how to deal with redundant/duplicated fields.
- Wrote OOP Framework to experiment on Logistic Regression hyperparameters and input data, using pickle decorators for low-code file staging, preventing unnecessary experiment reruns.
- Compared quality of Singular Value Decomposition and Transformer models on Information Retrieval task.

Holden Hunt:

- Created the program flow diagram.
- Finding the dataset, searched extensively and stumbled upon it and pointed our direction to using complaints and recalls.
- Wrote the code for converting audio recordings to text so it can be used as a query text input.
- Wrote the code for data processing text that tokenizes, vectorizes, and performs dimensionality reduction. Allowing for it to be used for cosine similarity, which I also wrote.
- Wrote the code for encoding component descriptions, so they could be used in classification models, which I also wrote.
- Wrote the code for using/ creating pickle files for the different python objects, models, and data frames, so the code would not have to extract and parse all the data each run. Allowing for the program to run quicker.
- Functionalized code so it could be called from Streamlit in an abstract manner.
- Wrote and designed the Streamlit interface.
- Wrote the readme and how to use Streamlit.

# References

[1] Gbihani, Gaurav. “NLP-Based Complaint Resolution on Automotive Manufacturing Data.” *Gaurav Bhihani's Blog*, 17 Nov. 2020, [https://www.gbihani.com/post/nlp-based-complaint-resolution-on-automotive-manufacturing-data/](https://www.gbihani.com/post/nlp-based-complaint-resolution-on-automotive-manufacturing-data/). Accessed 21 Apr. 2025.

[2] McCormick, Chris. “BERT Word Embeddings Tutorial.” *McCormickML*, 14 May 2019, [https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#1-loading-pre-trained-bert](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#1-loading-pre-trained-bert). Accessed 21 Apr. 2025.

[3] Tabrizi, Mehdi Reza. “Mastering Text Clustering with Python: A Comprehensive Guide.” *Medium*, 7 Nov. 2022, [https://medium.com/@mehdirt/mastering-text-clustering-with-python-a-comprehensive-guide-f8617f53c327](https://medium.com/@mehdirt/mastering-text-clustering-with-python-a-comprehensive-guide-f8617f53c327). Accessed 21 Apr. 2025.

[4] National Highway Traffic Safety Administration. *Recall Data File (RCL.txt)*. U.S. Department of Transportation, [https://static.nhtsa.gov/odi/ffdd/rcl/RCL.txt](https://static.nhtsa.gov/odi/ffdd/rcl/RCL.txt). Accessed 21 Apr. 2025.

[5] National Highway Traffic Safety Administration. *Complaint Data File (CMPL.txt)*. U.S. Department of Transportation, [https://static.nhtsa.gov/odi/ffdd/cmpl/CMPL.txt](https://static.nhtsa.gov/odi/ffdd/cmpl/CMPL.txt). Accessed 21 Apr. 2025.

# **Appendix:**

## Section 1 Full Dataset Field Description for Combined Recall/Complaint Table:

| Field Name | Type | Description |
| --- | --- | --- |
| ODINO | STRING | Internal NHTSA reference number |
| MFR_NAME | STRING | Manufacturer name |
| MAKETXT | STRING | Vehicle or equipment make |
| MODELTXT | STRING | Model name |
| YEARTXT | INTEGER | Model year |
| CRASH | STRING (Y/N) | Was vehicle involved in a crash |
| FAILDATE | DATE | Incident date (YYYYMMDD) |
| FIRE | STRING (Y/N) | Was fire involved |
| INJURED | INTEGER | Number of injuries |
| DEATHS | INTEGER | Number of fatalities |
| COMPDESC | STRING | Complaint component description |
| CITY | STRING | Consumer city |
| STATE | STRING | Consumer state abbreviation |
| VIN | STRING | Vehicle Identification Number (partial) |
| DATEA | DATE | Date added to NHTSA database |
| LDATE | DATE | Date complaint received |
| CMPL_TYPE | STRING | Complaint source code (e.g., IVOQ) |
| POLICE_RPT_YN | STRING (Y/N) | Incident reported to police |
| ORIG_OWNER_YN | STRING (Y/N) | Original owner status |
| ANTI_BRAKES_YN | STRING (Y/N) | Anti-lock brakes present |
| CRUISE_CONT_YN | STRING (Y/N) | Cruise control present |
| FUEL_TYPE | STRING | Fuel type (e.g., GS, HE) |
| DOT | STRING | Tire DOT code |
| LOC_OF_TIRE | STRING | Tire location (e.g., FSW, PSR) |
| TIRE_FAIL_TYPE | STRING | Tire failure code (e.g., BLW) |
| ORIG_EQUIP_YN | STRING (Y/N) | Is part original equipment |
| SEAT_TYPE | STRING | Child seat type (e.g., C, B, I) |
| RESTRAINT_TYPE | STRING | Restraint system (A = seatbelt, B = LATCH) |
| DEALER_NAME | STRING | Dealer name |
| DEALER_CITY | STRING | Dealer city |
| DEALER_STATE | STRING | Dealer state |
| PROD_TYPE | STRING | Product type (V, T, E, C) |
| REPAIRED_YN | STRING (Y/N) | Was the product repaired |
| VEHICLES_TOWED_YN | STRING (Y/N) | Was vehicle towed |
| MMYTXT | STRING | Concatenated Make Model Year (e.g., TOYOTA TUNDRA 2024) |
| VEH_SPEED | FLOAT | Vehicle speed at time of incident |
| DRIVE_TRAIN | STRING | Drive train type (e.g., AWD, FWD) |
| OCCURENCES | INTEGER | Number of occurrences |
| PURCH_DT | DATE | Purchase date |
| NUM_CYLS | INTEGER | Number of cylinders |
| CDESCR | TEXT | Complaint narrative |
| MEDICAL_ATTN | STRING (Y/N) | Was medical attention required |
| MILES | INTEGER | Vehicle mileage at time of failure |
| DEALER_ZIP | STRING | Dealer ZIP code |
| FUEL_SYS | STRING | Fuel system type |
| TRANS_TYPE | STRING | Transmission type (AUTO, MAN) |
| DEALER_TEL | STRING | Dealer telephone number |
| MANUF_DT | DATE | Date of manufacture |
| TIRE_SIZE | STRING | Tire size |
| NUMRECORDS | INTEGER | Count field (likely for aggregation) |
| IS_COMPLAINT | BOOLEAN | True if row is from complaint data |
| RECORD_ID | INTEGER | Unique identifier from RECALLS |
| CAMPNO | STRING | NHTSA campaign number |
| MFGCAMPNO | STRING | Manufacturer campaign number |
| RCLTYPECD | STRING | Recall type code |
| POTAFF | INTEGER | Potential number of affected units |
| ODATE | DATE | Date owners were notified |
| INFLUENCED_BY | STRING | Recall initiator (MFR/OVSC/ODI) |
| MFGTXT | STRING | Manufacturer of recalled product |
| RCDATE | DATE | Report received date |
| CORRECTIVE_ACTION | TEXT | Summary of corrective actions taken |
| NOTES | TEXT | Recall notes |
| RCL_CMPT_ID | STRING | Unique recalled component ID |
| MFR_COMP_NAME | STRING | Component name (manufacturer-supplied) |
| MFR_COMP_DESC | STRING | Component description |
| MFR_COMP_PTNO | STRING | Component part number |
| DESC_DEFECT | TEXT | Summary of defect |
| FMVSS | STRING | FMVSS code |
| CONSEQUENCE_DEFECT | TEXT | Consequence summary |
| ENDMAN | DATE | End date of manufacturing |
| RPNO | STRING | Regulation part number |
| BGMAN | DATE | Begin date of manufacturing |

## Section 2 Information Retrieval Query Examples:

- **Query: Speaker Rattles (TruncatedSVD 384 dimensions)**
    
    
    | **CDESCR** | **similarity** | **IS_COMPLAINT** |
    | --- | --- | --- |
    | There has been a problem going on with my 2016 Honda Accord Touring and it’s unbelievably terrible it has something to do with the sound system in the car and it can’t be stopped even if you try to power off the Radio it still occurs and it’s an on going problem until the vehicle is powered off, basically it’s a static noise that comes through all speakers that starts off not too loud then it gets really loud! To where you can’t even hear the person in the passenger seat and it is so bad it can possibly cause hearing damage and also to mention you can’t hear any sirens of like an ambulance for instance it happened to me other day where an ambulance was behind me and I didn’t hear it because of the horrible static sound coming from the speakers I found out the ambulance was behind me because of the cars in front of me pulling over to the side of the road and also I have little cousins and I would to go on trips with them but it worries me I can hurt their ears and they might start to panic to how bad the sound is. | 0.516815 | True |
    | I have a 2016 Honda Accord and I am experiencing a very loud sound of static coming from the speakers and it has become unbearable. I can't turn the volume down or turn the radio off and when I try the noise is still there. I have been having to shut the engine off and sit with the car off in order for the noise to stop. | 0.483981 | True |
    | Uncontrollably loud static noise coming from speakers, even when the head unit is turned off. This noise gets so loud, it becomes a safety issue and a distraction while driving. This noise cannot be turned down or off. | 0.438910 | True |
    | In December the vehicle started showing a pedestrian warning sound fault light. The pedestrian warning sound was replaced by a siren that sounds like an air raid siren which makes the car virtually undriveable. | 0.435719 | True |
    | When I take sharp turns the passenger side has a loud clicking sound. It's concerning after less than 600 miles there is a loud clicking sound. | 0.435428 | True |
    | Unknown other than noise and knocking | 0.414502 | True |
    | The audio system has become inoperable and instead the speakers are blasting static noise with crackling and popping sounds at high volume. Cannot stop it or use any other audio. Very unsafe to drive due to extreme noise level and lack of controls. Appears many people have this issue and there needs to be a recall to fix. | 0.413727 | True |
- **Query: Speaker Rattles (All-MiniLM-v2 384 dimensions)**
    
    ❗Bias towards exact keyword matches. For example, top result “window rattling” is not a “speaker rattling” problem.
    
    ---
    
    | **CDESCR** | **similarity** | **IS_COMPLAINT** |
    | --- | --- | --- |
    | All the windows make a rattling noise when they're rolled halfway down when hitting bumps. | 0.560351 | True |
    | Driving down the highway and all of a sudden the speakers made a sound like a gun going of then they all started popping at a deafening level. Was unable to focus or hear anything and almost was hit by another car before I could get safely pulled over, sat for nearly 2 hours turning on ignition periodically to see if it would stop finally it did. Looked online and there are numerous posts abou... | 0.506577 | True |
    | Rattling sound when the car is started - this is happening every time. MPG dropped from 42 to 30.. | 0.503734 | True |
    | The audio system has become inoperable and instead the speakers are blasting static noise with crackling and popping sounds at high volume. Cannot stop it or use any other audio. Very unsafe to drive due to extreme noise level and lack of controls. Appears many people have this issue and there needs to be a recall to fix. | 0.502711 | True |
    | When I start my truck, a very loud, piercing noise comes out of the speakers. The has happened 2 times over appx 2 years. The info screen on the dash freezes up. It can only be stop by turning the ignition off. | 0.501696 | True |
- **Query: Air Bag (TruncatedSVD 384 dimensions)**
    
    
    | **CDESCR** | **similarity** | **IS_COMPLAINT** |
    | --- | --- | --- |
    | Nissan North America, Inc. (INFINITI) is recalling certain 2003 INFINITI FX35, 2006-2008 FX35 and FX45 vehicles that previously received a replacement front passenger air bag assembly under recall number 20V-008. The air bag cushion was folded incorrectly, which could increase internal pressure and tear the air bag cushion during deployment. A tear in the air bag may decrease air bag performance, and increase the risk of injury. | 0.858358 | False |
    | Mercedes-Benz USA, LLC (MBUSA) is recalling certain 2020 GLB250 vehicles. The front passenger air bag inflator and cushion may be improperly attached inside the air bag module, which could result in the air bag cushion tearing upon deployment. An air bag that does not deploy properly during a crash can increase the risk of injury. | 0.841745 | False |
    | VEHICLE DESCRIPTION: PASSENGER VEHICLES. PASSENGER AIR BAGS WERE BUILT WITH SUSPECT ALUMINUM EXTRUSION SECTIONS WHICH MAY NOT RETAIN THE AIR BAG DOOR DURING AN AIR BAG DEPLOYMENT EVENT. A SEPARATED AIR BAG DOOR COULD INJURE A VEHICLE OCCUPANT. | 0.824086 | False |
- **Query: Air Bag (All-MiniLM-v2 384 dimensions)**
    
    ❗Bias towards short text length.
    
    | **CDESCR** | **similarity** | **IS_COMPLAINT** |
    | --- | --- | --- |
    | Service airbag | 0.750204 | True |
    | Air bags came out on own | 0.662780 | True |
    | Air bag in drivers seat deployed when I shut rear door. Car was running at the time. | 0.607215 | True |
    | Airbag light is on | 0.583204 | True |
    | THE ELECTRICAL CIRCUIT DESIGN ALLOWS THE POTENTIAL FOR AN INADVERTENT AIR BAG DEPLOYMENT UPON VEHICLE IGNITION SHUT DOWN. UNEXPECTED AIR BAG DEPLOYMENT CAN RESULT IN OCCUPANT INJURY. | 0.582704 | False |
    | THE PASSENGER SIDE AIR BAG HAS AN INFLATOR BODY THAT CRACKED DURING FORMING OF THE CURL THAT RETAINS THE IGNITER PLUG IN THE END OF THE INFLATOR. ALSO THE IGNITER END CAP CAN SEPARATE FROM THE INFLATOR. THE PASSENGER SIDE AIR BAG MAY NOT INFLATE PROPERLY RESULTING IN REDUCED OCCUPANT PROTECTION IN A VEHICLE ACCIDENT. IF THE IGNITER END CAP SEPARATES IN A FRONTAL COLLISION, HOT GASES CAN BE RELEASED AND IGNITE FLAMMABLE MATERIAL OR CAUSE BURN INJURIES. | 0.579548 | False |
- **Query: Air Bag Sensor Toggle (TruncatedSVD 384 dimensions)**
    
    
    | **CDESCR** | **similarity** | **IS_COMPLAINT** |
    | --- | --- | --- |
    | VEHICLE DESCRIPTION: PASSENGER VEHICLES. SOME AIR BAG SENSORS DO NOT COMPLY WITH AUDI'S DURABILITY STANDARDS OVER THE LIFETIME OF THE VEHICLE. IN THE EVENT THE SENSOR SHOULD MALFUNCTION, THE AIR BAG RESTRAINT SYSTEM CAN INADVERTENTLY DEPLOY. DEPLOYMENT OF THE AIR BAG RESTRAINT SYSTEM WITHOUT WARNING COULD CAUSE A DRIVER TO LOSE VEHICLE CONTROL. | 0.728836 | False |
    | THE TWO AIR BAG SYSTEM FRONT IMPACT SENSORS MAY NOT BE SECURED TO THEIR MOUNTING BRACKETS. AIR BAG WILL NOT DEPLOY IN A FRONTAL COLLISION IF THEFRONT IMPACT SENSORS ARE NOT ATTACHED. | 0.717320 | False |
    | Toyota Motor Engineering & Manufacturing (Toyota) is recalling certain 2019 Sienna vehicles. The passenger front door may have incorrect welds inside, possibly affecting the air bag sensor readings for the passenger side front seat and curtain shield air bags. The incorrect air bag sensor readings could cause the affected air bags to unintentionally deploy or to not deploy when intended, increasing the risk of a crash and/or injury. | 0.708586 | False |
    | Toyota Motor Engineering & Manufacturing (Toyota) is recalling certain 2016 Toyota Prius and Lexus RX 350, RX 350 F Sport, RX 450h F Sport and RX 450h vehicles and 2015-2016 Lexus NX 200T, NX Turbo and NX 300h vehicles. The air bag pressure sensors and/or the acceleration sensors may fail causing the side/curtain shield air bags and/or the front air bags to not deploy in the event of a crash. If the air bags fail to deploy in a crash, it can increase the risk of injury. | 0.686543 | False |
    | VEHICLE DESCRIPTION: PASSENGER VEHICLES. THE SUPPLEMENTAL RESTRAINT SYSTEM SIDE AIR BAG SATELLITE SENSORS INSTALLED WERE IMPROPERLY MANUFACTURED, CAUSING THE AIR BAG WARNING LIGHT TO ILLUMINATE AND THE SIDE AIR BAGS TO NOT DEPLOY AS INTENDED IN THE EVENT OF A CRASH. NON-DEPLOYMENT OF THE SIDE AIR BAGS COULD INCREASE THE RISK OF INJURY DURING A CRASH WHERE SIDE AIR BAG DEPLOYMENT IS INTENDED. | 0.683700 | False |
    |  |  |  |
- **Query: Air Bag Sensor Toggle (All-MiniLM-v2 384 dimensions)**
    
    
    | **CDESCR** | **similarity** | **IS_COMPLAINT** |
    | --- | --- | --- |
    | Airbag light is on. Airbag sensor is out. | 0.684502 | True |
    | EQUIPMENT DESCRIPTION: THE AIR BAG ON/OFF SWITCH ASSEMBLIES DO NOT PROVIDE A SEPARATE LIGHT TO INDICATE THAT AN AIR BAG HAS BEEN TEMPORARILY SWITCHED OFF OR DISABLED. ALSO, THE VEHICLE'S AIR BAG READINESS INDICATOR LAMP STAYS ON WHEN AN AIR BAG IS DISABLED. THE VEHICLE OCCUPANT IS UNAWARE THAT THE AIRBAG HAS BEEN SWITCHED OFF OR DISABLED WHICH COULD RESULT IN INJURY IN A CRASH. ALSO, THE OCCUPANT IS UNAWARE OF ANY FAILURE OR MALFUNCTION THAT MAY BE DETECTED BY THE VEHICLE'S AIR BAG MONITORING SYSTEM BECAUSE THE AIR BAG INDICATOR LAMP STAYS ON WHEN AN AIR BAG IS DISABLED. | 0.597407 | False |
    | Air Bag Warning Light | 0.596064 | True |
    | Airbag light is on | 0.595776 | True |
    | Randomly the passenger airbag indicator light comes on and a notification to check airbag | 0.572885 | True |
    | VEHICLE DESCRIPTION: PASSENGER VEHICLES. SOME AIR BAG SENSORS DO NOT COMPLY WITH AUDI'S DURABILITY STANDARDS OVER THE LIFETIME OF THE VEHICLE. IN THE EVENT THE SENSOR SHOULD MALFUNCTION, THE AIR BAG RESTRAINT SYSTEM CAN INADVERTENTLY DEPLOY. DEPLOYMENT OF THE AIR BAG RESTRAINT SYSTEM WITHOUT WARNING COULD CAUSE A DRIVER TO LOSE VEHICLE CONTROL. | 0.568371 | False |
    | Passenger side seat airbag sensor not working warning light and massages indicate airbag restraint issue. | 0.564858 | True |
    | Air bag light is on constantly, goes off if my steering wheel is turned a certain way. But will come back on immediately after if turned and will not go off of dashboard | 0.557601 | True |
- **Query: Bad Smell Brake Pads Overheating (TruncatedSVD 384 dimensions)**
    
    
    | **CDESCR** | **similarity** | **IS_COMPLAINT** |
    | --- | --- | --- |
    | THERE IS INADEQUATE CLEARANCE BETWEEN THE FRONT DISC PADS AND THE CALIPER ASSEMBLY. HEAT BUILD UP CAN CAUSE THE BRAKE PAD BACKING PLATE TO EXPAND AND BIND IN THE CALIPER. THE BRAKE PADS WILL CONTINUOUSLY CONTACT THE BRAKE ROTOR, OVERHEATING THE FRONT ROTOR. THE EXPANSION OF THE BRAKE PAD BACKING PLATE WILL CAUSETHE BRAKE PADS TO CONTINUOUSLY CONTACT THE BRAKE ROTOR AND OVERHEAT THE FRONTROTOR; CAUSING THE FRONT BRAKE ROTOR TO DISTORT, DECREASING BRAKE PERFORMANCEAND CAUSING LONGER STOPPING DISTANCES WHICH COULD RESULT IN AN ACCIDENT. | 0.694829 | False |
    | Brembo S.p.A. (Brembo) is recalling certain federal Mogul rear brake pads. During braking, the brake pad material may detach from the back plate, which can affect the braking performance in slowing the vehicle. If the brake pad friction material detaches it can, inhibit braking ability, increasing the risk of injury and crash. | 0.652711 | False |
    | Vehicle has had 3 instances of a feeling of locking/ seizing and shutter or hesitation during braking at 40 to 65 MPH. Service light appear about brake system which quickly vanishes in less than few seconds same as feeling of the brake seizing also disappears within few seconds. This occurred from initial purchase to date at 21k miles. Vehicle brake system inspected at this service junction 2 years after purchase and at this service at 21k one single brake pad and rotor has worn on right front brake pad to 3mm. Front right Brake rotor also deemed damaged and require changing. Other 3 brakes pads and rotors meaning left front brake pad and rotor and 2 rear brake pads and rotors are in good condition at 8mm. The dealership has issued a finding from their independent warranty inspection people who refute that the brake caliper as deemed as cause of this issue in past cases have now instructed the dealerships to NOT change caliper but just change the brake and rotor affected and to do this at the vehicle owner's expense nonetheless. So the vehicle has has other identified issues with uneven brake wear of the model 2022 MDX Type S. The manufacturer is not acting in good faith to provide safe and reasonable means of addressing this issue. This issue is clearly happening to this particular MDX and now Acura does not want to find the problem and correct it. My brake has worn to 3mm and yet it is not considered a "defective" part that must be at fault? There needs to be an identification of what can be causing this as brakes are one of the major safety components for a vehicle. Acura needs to find out the cause and stop passing the responsibility of correcting an obvious defect onto the consumer with a bandaid. Changing the rotor and brake pad is not the way. The root defect needs to be addressed especially since there is obviously multiple people with same issue with this make and model 2022. | 0.594575 | True |
    | Genuine Scooters, LLC. (Genuine Scooters) is recalling certain 2020 Royal Alloy GT150 scooters. The front brake rotor may become uncentered within the front brake caliper allowing the inner brake pad to dislodge from the top of the brake caliper. If the brake pad becomes dislodged, the scooter can experience a reduced or complete loss of braking, increasing the risk of a crash. | 0.579921 | False |
    | Brembo S.p.A (Brembo) is recalling certain Brembo brake pads, model BRM10B, part number 07988236/07B80923. The Tungaloy pads could corrode, and potentially cause detachment of the brake pad friction material from the backing plate. If the brake pad friction material detaches from the backing plate, it may lengthen the stopping distance needed, increasing the risk of a crash. | 0.560229 | False |
    |  |  |  |
- **Query: Bad Smell Brake Pads Overheating (All-MiniLM-v2 384 dimensions)**
    
    
    | **CDESCR** | **similarity** | **IS_COMPLAINT** |
    | --- | --- | --- |
    | THERE IS INADEQUATE CLEARANCE BETWEEN THE FRONT DISC PADS AND THE CALIPER ASSEMBLY. HEAT BUILD UP CAN CAUSE THE BRAKE PAD BACKING PLATE TO EXPAND AND BIND IN THE CALIPER. THE BRAKE PADS WILL CONTINUOUSLY CONTACT THE BRAKE ROTOR, OVERHEATING THE FRONT ROTOR. THE EXPANSION OF THE BRAKE PAD BACKING PLATE WILL CAUSETHE BRAKE PADS TO CONTINUOUSLY CONTACT THE BRAKE ROTOR AND OVERHEAT THE FRONTROTOR; CAUSING THE FRONT BRAKE ROTOR TO DISTORT, DECREASING BRAKE PERFORMANCEAND CAUSING LONGER STOPPING DISTANCES WHICH COULD RESULT IN AN ACCIDENT. | 0.554119 | False |
    | CERTAIN REAR BRAKE CALIPERS COULD BIND AND CONSEQUENTLY OVERHEAT. OVERHEATED CALIPERS COULD CAUSE BRAKE PEDAL TO FEELSPONGY AND COULD RESULT IN ONE BRAKE CIRCUIT BECOMING INOPERATIVE. BRAKINGABILITY WOULD BE AFFECTED. | 0.528510 | False |
    | BRAKE LINES IN THE ENGINE COMPARTMENT ARE ROUTED TOO NEAR THE LEFT EXHAUST MANIFOLD, CAUSING THE BRAKE FLUID TO OVERHEAT. BRAKE FLUID LOSES VISCOSITY WHEN IT OVERHEATS, CAUSINGLOSS OF BRAKES OR INCREASED VEHICLE STOPPING DISTANCE WHICH MAY RESULT IN ANACCIDENT. | 0.520700 | False |
    | CERTAIN MOTOR COACHES, MOTOR HOMES, COMMUTER COACHES, AND TRANSIT BUSES EQUIPPED WITH ARVIN-MERITOR DX 225 AIR DISC BRAKES, ARE EXPERIENCING EXCESSIVE SMOKE IN THE WHEEL AREA DUE TO OVERHEATING OF THE AIR DISC BRAKE PADS. A POTENTIAL FIRE IN THE WHEEL MAY OCCUR WHICH MAY RESULT IN PROPERTY DAMAGE OR PERSONAL INJURY. | 0.516300 | False |
    | ON CERTAIN MOTOR HOMES, THE BRAKE ASSEMBLIES EXHIBIT ELEVATED TEMPERATURES THAT CAN LEAD TO CATASTROPHIC DETERIORATION OF THE WHEEL END COMPONENTS SUCH AS BEARINGS, RACES, SPINDLES, KNUCKLES, SEALS, HUBS, ROTORS, PATCH BOLTS, CALIPERS, BRAKE PADS, AND ABS SENSORS. THIS COULD RESULT IN LOSS OF CONTROL, AND/OR THE POTENTIAL FOR A FIRE. | 0.487572 | False |

## Section 3 Data Exploration:

There was a lot of data exploration that was done to understand the data sets for this project. Below are multiple diagrams and plots to help understand the dataset that was used for this project that there was not enough room to put into the original write up.  

Word maps (comparing some intersection/non-intersection words in recalls and complaints). This exploration was to potentially prevent data leakage/improve IR/clustering based on it. Since the majority of the models and methods required tokenizing text to get the data into vector space it was important to understand frequent and common words. 

![image.png](image%2017.png)

![image.png](image%2018.png)

![image.png](image%2019.png)

![image.png](image%2020.png)

![image.png](image%2021.png)

![image.png](image%2022.png)

![image.png](image%2023.png)

Data exploration, This was helped with understanding typical length of a documents text in character length.

![image.png](image%2024.png)

![image.png](image%2025.png)

![image.png](image%2026.png)

![image.png](image%2027.png)

Bar charts to show which makes have the most complaints and recalls associated with them.

![image.png](image%2028.png)

![image.png](image%2029.png)